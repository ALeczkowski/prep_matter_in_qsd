{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15b6e09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1398,
     "status": "ok",
     "timestamp": 1639689185152,
     "user": {
      "displayName": "Aleksander Leczkowski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05469543576572858132"
     },
     "user_tz": -60
    },
    "id": "d15b6e09",
    "outputId": "2bb5490a-509a-4f5d-ec55-7e3ccd100b0a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import svm \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "from approximation_algorithm import create_pred_tdag\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "045ec226",
   "metadata": {
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1639689227525,
     "user": {
      "displayName": "Aleksander Leczkowski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05469543576572858132"
     },
     "user_tz": -60
    },
    "id": "045ec226"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../quantifiers_prep_matter_in_qsd.xls\", index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b1efad5-1f3b-47e0-9434-4f13be171205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(680, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9078d3-45a9-4162-a983-ad8ebfb2c02b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test.no</th>\n",
       "      <th>q.no</th>\n",
       "      <th>sent.no</th>\n",
       "      <th>sentences</th>\n",
       "      <th>scopes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case.no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exactly six&amp;2_S_exactly.six.appositive# trade ...</td>\n",
       "      <td>b&gt;a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>There are exactly six&amp;2_P_exactly.six# chairs ...</td>\n",
       "      <td>b&gt;a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Each&amp;1_S_each# chair is occupied by exactly on...</td>\n",
       "      <td>a&gt;b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A&amp;1_S_a# small software firm has four&amp;2_O_four...</td>\n",
       "      <td>a&gt;b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Each&amp;1_S_each# of its offices has exactly one&amp;...</td>\n",
       "      <td>a&gt;b,c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test.no  q.no  sent.no  \\\n",
       "case.no                           \n",
       "1              1     1      1.0   \n",
       "2              1     1      2.0   \n",
       "4              1     1      4.0   \n",
       "9              1     2      1.0   \n",
       "10             1     2      2.0   \n",
       "\n",
       "                                                 sentences scopes  \n",
       "case.no                                                            \n",
       "1        Exactly six&2_S_exactly.six.appositive# trade ...    b>a  \n",
       "2        There are exactly six&2_P_exactly.six# chairs ...    b>a  \n",
       "4        Each&1_S_each# chair is occupied by exactly on...    a>b  \n",
       "9        A&1_S_a# small software firm has four&2_O_four...    a>b  \n",
       "10       Each&1_S_each# of its offices has exactly one&...  a>b,c  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d71d292",
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1639691822674,
     "user": {
      "displayName": "Aleksander Leczkowski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05469543576572858132"
     },
     "user_tz": -60
    },
    "id": "3d71d292"
   },
   "outputs": [],
   "source": [
    "# Some examples (to test functions):\n",
    "test_annot = \"Each&1_S_each# member of the Kim family sits in a&3_in_a_p.Locus_p.Locus# seat adjacent to, and in the same row&3_in_the.same_p.Locus_p.Locus# as, at least one other&2_as_at.least.one.other_p.ComparisonRef_p.ComparisonRef# member of the family.\"\n",
    "test_scope = \"a>d>b,c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3eb63f-cedf-48a7-826e-d9fd5f808bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Intitialize sets to store information.\n",
    "Define some constants.\n",
    "\"\"\"\n",
    "R_GRAMM = ['S', 'O', 'IO', 'P', 'A', \"'s\"] # Gramamtical roles present in the corpus\n",
    "ALL_LEX = set() # a set of all possible lexicalizations of quantifiers\n",
    "ALL_ROLES = set() # should equal to the list 'R_GRAMM'\n",
    "ALL_PREP = set() # a set of all prepositions in the corpus\n",
    "ALL_SS2 = set() # a -||- ss2\n",
    "ALL_SSSS2 = set() # a -||- ss+ss2 combinations\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "TEST_RATIO = 0.2\n",
    "\n",
    "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd668023",
   "metadata": {
    "id": "dd668023",
    "tags": []
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c66cb254",
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1639689239025,
     "user": {
      "displayName": "Aleksander Leczkowski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05469543576572858132"
     },
     "user_tz": -60
    },
    "id": "c66cb254"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fills in sets defined in the previous cell and returns a list of lists of annotations.\n",
    "\n",
    "The beggining of each tag is marked with '&' and the end with '#'. \n",
    "\n",
    "First spot is occupied by a number that corresponds to the relative scope of a given quantifier in a given sentence.\n",
    "Second spot is either a gramamtical role of a given tag or a preposition if a given tag is a prepositional phrase.\n",
    "Third position representes the quantifier lexicalisation.\n",
    "Fourth and fifth positions are present only if the phrase is a prepositional phrase and correspond to supersenses, SS \n",
    "and SS2 respectively.\n",
    "\"\"\"\n",
    "\n",
    "def extract_annotations(corpus_sentence):\n",
    "    annotations = []\n",
    "    i = 0\n",
    "    p = re.compile(r'&.+?#') # Each tag starts with '&' and ends with '#'\n",
    "    for m in re.finditer(p, corpus_sentence):\n",
    "        annotation = m.group()[1:-1].split('_')\n",
    "        # Temporal adjuncts such as 'Each day' are additionaly tagged in the corpus with supersenses p.Time_p.Time. \n",
    "        # We do not want to include those supersenses in the experiment since there is no explicit preposition here.\n",
    "        if annotation[-1] == 'p.Time' and annotation[-2] == 'p.Time' and annotation[1] == 'A':\n",
    "            annotation = annotation[:-2]\n",
    "        \n",
    "        if annotation[-1].startswith('p.'):\n",
    "            ALL_SS2.add(annotation[-1])\n",
    "            ALL_SSSS2.add(annotation[-2] + '_' + annotation[-1])\n",
    "        if annotation[1] in R_GRAMM:\n",
    "            ALL_ROLES.add(annotation[1])\n",
    "        if annotation[1] not in R_GRAMM:\n",
    "            ALL_PREP.add(annotation[1])\n",
    "        \n",
    "        ALL_LEX.add(annotation[2])\n",
    "    \n",
    "        # For each sentence and each quantifier (tag) in it add a letter at the end of the tag that will distinguish it\n",
    "        annotation.append(ALPHABET[i])\n",
    "        \n",
    "        annotations.append(annotation)      \n",
    "        i += 1\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f342b5c7",
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1639689241607,
     "user": {
      "displayName": "Aleksander Leczkowski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05469543576572858132"
     },
     "user_tz": -60
    },
    "id": "f342b5c7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns a list of lists of quantifier annotations.\n",
    "\"\"\"\n",
    "\n",
    "def annotations(data):\n",
    "    all_annotations = []\n",
    "    for index, row in data.iterrows():\n",
    "        all_annotations.append(extract_annotations(row['sentences']))\n",
    "    return all_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d7a982-9b0e-49de-bacb-0f5ef9a8b434",
   "metadata": {},
   "source": [
    "### Create a list of annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec178c13-600a-49eb-9e4a-fb8965cd606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Populate the list of lists representing quantifier annotations for each sentence.\n",
    "\"\"\"\n",
    "ALL_ANNOTATIONS = annotations(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa848035-5e86-4d24-8ef4-0c158e750288",
   "metadata": {},
   "source": [
    "## Corpus statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad32b646-79a1-4788-9bbb-6c01db837892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of sentences in the corpus:  680 \n",
      " Number of tags in the corpus:  1679 \n",
      " Number of tags in the corpus that are nested in prepositional phrases:  581 \n",
      " Number of relations/observations:  1451\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell computes some corpus statistics\n",
    "\"\"\"\n",
    "\n",
    "nb_sent = 0 # Number of sentences in the corpus\n",
    "nb_tags = 0 # Number of tags in the corpus\n",
    "nb_tags_pp = 0 # Number of tags that are nested in prepositional phrases\n",
    "nb_of_relations = 0 # Number of observations/relations\n",
    "for sent in ALL_ANNOTATIONS:\n",
    "    nb_of_relations += len(sent)*(len(sent)-1)/2\n",
    "    nb_sent += 1\n",
    "    for el in sent:\n",
    "        nb_tags += 1\n",
    "        if el[1] in ALL_PREP:\n",
    "            nb_tags_pp += 1\n",
    "\n",
    "print(\n",
    "      ' Number of sentences in the corpus: ', nb_sent, '\\n',\n",
    "      'Number of tags in the corpus: ', nb_tags, '\\n',\n",
    "      'Number of tags in the corpus that are nested in prepositional phrases: ', nb_tags_pp, '\\n',\n",
    "      'Number of relations/observations: ', int(nb_of_relations)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd7741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of different gramamtical roles annotated:  6 \n",
      " Number of different quantifier lexicalisations:  184 \n",
      " Number of different preposition lexicalisations:  27 \n",
      " Number of different ss2:  26 \n",
      " Number of different ss+ss2 combinations:  67 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell presents some more corpus statistics.\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    ' Number of different gramamtical roles annotated: ', len(ALL_ROLES), '\\n',\n",
    "    'Number of different quantifier lexicalisations: ', len(ALL_LEX), '\\n',\n",
    "    # Quantifier lexicalisations are later combined into groups\n",
    "    'Number of different preposition lexicalisations: ', len(ALL_PREP), '\\n',\n",
    "    'Number of different ss2: ', len(ALL_SS2), '\\n',\n",
    "    'Number of different ss+ss2 combinations: ', len(ALL_SSSS2), '\\n',\n",
    "     \n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68dbb7d",
   "metadata": {
    "id": "d68dbb7d"
   },
   "source": [
    "# Graphs and scope extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a3248ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1639691828705,
     "user": {
      "displayName": "Aleksander Leczkowski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05469543576572858132"
     },
     "user_tz": -60
    },
    "id": "9a3248ff",
    "outputId": "ac4fd2a3-4360-47f2-b3f1-a5581fb4088c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a>d>b,c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'a', 'b', 'c', 'd'}, {('a', 'd'), ('d', 'b'), ('d', 'c')})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "These three functions extract pairwise comparisons relations from sentence's scopings. \n",
    "An input is a sentence's scope (e.g. 'a>b>c,d').\n",
    "Function 'extract_scopes' returns a set of nodes (quantifiers in a given sentence) and a set of outscoping relations. \n",
    "The set consists of tuples sorted such that if 'a>b' then '(a,b)' and if 'b>a' then '(b,a)'.\n",
    "\"\"\"\n",
    "\n",
    "def extract_scopes(scope):\n",
    "    edges = []\n",
    "    nodes = set()\n",
    "    for i in range(len(scope)):\n",
    "        if scope[i] == \">\":\n",
    "            edges.append((scope[i-1], scope[i+1]))\n",
    "            if scope[i-2] == \",\":\n",
    "                ab = check_before(scope, i-1)\n",
    "                edges.extend(ab)\n",
    "            if i < len(scope)-2 and scope[i+2] == \",\":\n",
    "                af = check_after(scope, i+1)\n",
    "                edges.extend(af)\n",
    "        if scope[i].isalpha():\n",
    "            nodes.add(scope[i])\n",
    "    edges = set(edges)\n",
    "    return nodes, edges\n",
    "\n",
    "def check_before(scope, j):\n",
    "    l = []\n",
    "    for i in range(j):\n",
    "        if scope[j-i] == \",\":\n",
    "            l.append((scope[j-i-1], scope[j+2]))\n",
    "        elif scope[j-i] == \">\" or scope[j-i] == \";\":\n",
    "            break\n",
    "    return l\n",
    "\n",
    "def check_after(scope, j):\n",
    "    l = []\n",
    "    for i in range(len(scope)-j):\n",
    "        if scope[j+i] == \",\":\n",
    "            l.append((scope[j-2], scope[j+i+1]))\n",
    "        elif scope[j+i] == \">\" or scope[j+i] == \";\":\n",
    "            break\n",
    "    return l\n",
    "\n",
    "print(test_scope)\n",
    "extract_scopes(test_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b866b26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1639691832802,
     "user": {
      "displayName": "Aleksander Leczkowski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05469543576572858132"
     },
     "user_tz": -60
    },
    "id": "8b866b26",
    "outputId": "b1487441-1898-4d5c-ee74-d64bb72dba87"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Making use of the functions defined in the previous cell, this function returns a Directed Acylic Graph (DAG)\n",
    "that represents each sentence's quantifier scoping.\n",
    "\"\"\"\n",
    "def build_dag(scope):\n",
    "    nodes, edges = extract_scopes(scope)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "    if not nx.is_directed_acyclic_graph(G):\n",
    "        print('STOP! This graph is not a DAG!')\n",
    "    return G\n",
    "\n",
    "G = build_dag(test_scope)\n",
    "nx.draw(G, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d206f",
   "metadata": {
    "id": "845d206f"
   },
   "source": [
    "### Labels\n",
    "\n",
    "Three classes that the classifier will predict: \\\n",
    "0 --> incomparability relation \\\n",
    "1 --> wide scope \\\n",
    "2 --> narrow scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b429dc5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1639689471036,
     "user": {
      "displayName": "Aleksander Leczkowski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05469543576572858132"
     },
     "user_tz": -60
    },
    "id": "b429dc5d",
    "outputId": "8e263347-fd3f-48ff-ac80-34a12d0904f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a>d>b,c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('a', 'b'): '1',\n",
       " ('a', 'c'): '1',\n",
       " ('a', 'd'): '1',\n",
       " ('b', 'c'): '0',\n",
       " ('b', 'd'): '2',\n",
       " ('c', 'd'): '2'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given the labels defined above, by taking the transitive closure of DAGs that represent each sentence's scoping, \n",
    "this function returns a dictionary where keys are tuples that correspond to a pair of quantifiers - an observation -\n",
    "(always sorted as (q1, q2), where q1 occurs before q2 in a given sentence) and values are classes to be predicted: \n",
    "incomparability relation, wide scope or narrow scope.\n",
    "\"\"\"\n",
    "\n",
    "def graph_to_dict_closure(scope):\n",
    "    G = build_dag(scope)\n",
    "    G_closure = nx.transitive_closure(G)\n",
    "    all_nodes = sorted(list(G_closure.nodes))\n",
    "    all_edges = list(G_closure.edges)\n",
    "    comparisons = {}\n",
    "    for a, b in itertools.combinations(all_nodes, 2):\n",
    "        if (a, b) in all_edges:\n",
    "            comparisons[(a, b)] = '1' # wide scope\n",
    "        elif (b, a) in all_edges:\n",
    "            comparisons[(a, b)] = '2' # narrow scope\n",
    "        else:\n",
    "            comparisons[(a, b)] = '0' # if there is no edge then the two quantifiers are in an incomparability relation\n",
    "    return comparisons\n",
    "print(test_scope)\n",
    "graph_to_dict_closure(test_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d3405d",
   "metadata": {
    "id": "c8d3405d"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a list of dictionaries where each dictionary lists pairs of quantifiers from a sentence and relations between \n",
    "those pairs.\n",
    "\"\"\"\n",
    "\n",
    "def scopes(data):\n",
    "    all_scopes = []\n",
    "    for index, row in data.iterrows():\n",
    "            all_scopes.append(graph_to_dict_closure(row['scopes']))\n",
    "    return all_scopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b27bd",
   "metadata": {
    "id": "064b27bd"
   },
   "source": [
    "### Create a list of scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "647b7223",
   "metadata": {
    "id": "647b7223"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Populate the list of lists representing quantifier annotations for each sentence.\n",
    "\"\"\"\n",
    "ALL_SCOPES = scopes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5af8b998-c5b9-4b3a-bb54-3ce9d279df7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of wide scopes:  828 \n",
      " Number of narrow scopes:  307 \n",
      " Number of incomparability relations:  316 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell computes population of classes.\n",
    "\"\"\"\n",
    "\n",
    "wide = 0\n",
    "narrow = 0\n",
    "incomp = 0\n",
    "for el in ALL_SCOPES:\n",
    "    for k, v in el.items():\n",
    "        if v == '0':\n",
    "            incomp += 1\n",
    "        elif v == '1':\n",
    "            wide += 1\n",
    "        else:\n",
    "            narrow += 1\n",
    "print(\n",
    "      ' Number of wide scopes: ', wide, '\\n',\n",
    "      'Number of narrow scopes: ', narrow, '\\n',\n",
    "      'Number of incomparability relations: ', incomp, '\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7630671-3132-437d-b2dc-1baff4c87a3f",
   "metadata": {},
   "source": [
    "## Define data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "707db17f",
   "metadata": {
    "id": "707db17f"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Models are trained multiple times with different train/test splits. \n",
    "This is why random state is the argument of the function.\n",
    "\n",
    "Note, however, that even though an observation in this experiment is a pair of quantifiers, the data needs to be split\n",
    "on a sentence level so that all observations (pairs of quantifiers) from the same sentence are located in the same data set.\n",
    "This way it is possible to restore the sentence's quantifier scoping once the predictions of the classifier are made.\n",
    "\"\"\"\n",
    "\n",
    "def split_data(X_data, y_data, r_state):\n",
    "    train_annot, test_annot, train_scope, test_scope = model_selection.train_test_split(X_data, y_data,\n",
    "                                                                                        train_size = TRAIN_RATIO,\n",
    "                                                                                        test_size = TEST_RATIO,\n",
    "                                                                                        random_state = r_state)\n",
    "    return train_annot, train_scope, test_annot, test_scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab199c-5d79-42e8-9324-1bc212142e89",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc5c120b",
   "metadata": {
    "id": "dc5c120b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Feature: COMPLEX\n",
    "\"\"\"\n",
    "A binary feature; a quantifier lexicalization is cosidered complex if it cosists of more than one word (e.g. 'more than one')\n",
    "('.appositive' refers to a different feature which was annotated in the corpus together with quantifier lexicalization)\n",
    "\n",
    "\"\"\"\n",
    "def is_complex(lexicalization):\n",
    "    if lexicalization.endswith('.appositive'): \n",
    "        lexicalization = lexicalization[:-len('.appositive')]\n",
    "    return 1. if len(lexicalization.split('.')) > 1 else 0.\n",
    "\n",
    "print(is_complex('more.than.one'))\n",
    "print(is_complex('each.appositive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af2fbf12",
   "metadata": {
    "id": "af2fbf12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Feature: APPOSITIVE\n",
    "\"\"\"\n",
    "A binary feature; denotes whether a quantified NP chunk is followed by an appositive.\n",
    "\"\"\"\n",
    "\n",
    "def appositive(lexicalization):\n",
    "    feature = 0.\n",
    "    if lexicalization.endswith('.appositive'):\n",
    "        feature = 1.\n",
    "    return feature\n",
    "\n",
    "print(appositive('some.appositive'))\n",
    "print(appositive('every'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b71fb54",
   "metadata": {
    "id": "7b71fb54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature: DISTANCE\n",
    "\"\"\"\n",
    "Distance between the two compared quantifiers.  Equals 1 if no quantifier is between two compared \n",
    "quantifiers in the sentence.\n",
    "\n",
    "For instance, in 'b>c>a' there are three observations for the classifier: (a,b), (a,c) and (b,c). \n",
    "The distance for the observations (a,b) and (b,c) equals 1. \n",
    "The distance in the case of observation (a,c) equals 2.\n",
    "\"\"\"\n",
    "\n",
    "def distance(sentence_annotation, first, second):\n",
    "    f = sentence_annotation.index(first)\n",
    "    s = sentence_annotation.index(second)\n",
    "    result = float(s - f) \n",
    "    return result\n",
    "\n",
    "distance(ALL_ANNOTATIONS[4], ALL_ANNOTATIONS[4][0], ALL_ANNOTATIONS[4][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ded0f039",
   "metadata": {
    "id": "ded0f039"
   },
   "outputs": [],
   "source": [
    "# Feature: Quantifier lexicalization\n",
    "\"\"\"\n",
    "Combines many of the quantifier lexicalisations into groups (in order to lower the dimensionality of this feature).\n",
    "For instance, all bare numerals are grouped together, all superlative modified numerals together, etc.\n",
    "\"\"\"\n",
    "\n",
    "numerals = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', \n",
    "                'therteen', 'fourteen']\n",
    "the_numerals = ['the.' + n for n in numerals]\n",
    "consecutive_numerals = [n + '.consecutive' for n in numerals]\n",
    "\n",
    "def del_appositive(lex):\n",
    "    if lex.endswith('.appositive'): \n",
    "        lex = lex[:-len('.appositive')].lower()\n",
    "    return lex\n",
    "\n",
    "def prep_lex(all_lex):\n",
    "    all_lex_mod = []\n",
    "    for lex in list(all_lex):\n",
    "        lex = del_appositive(lex)\n",
    "        all_lex_mod.append(lex.lower())\n",
    "    return all_lex_mod\n",
    "\n",
    "def assign_group_lex(lex):\n",
    "    lex = lex.lower()\n",
    "    if lex.startswith('exactly'):\n",
    "        result = 'exactly.numerals'\n",
    "    elif lex.startswith('at.least') or lex.startswith('at.most'):\n",
    "        result = 'smn'\n",
    "    elif lex in numerals:\n",
    "        result = 'bare.numerals'\n",
    "    elif lex in the_numerals:\n",
    "        result = 'the.numerals'\n",
    "    elif lex in consecutive_numerals:\n",
    "        result = 'consecutive.numerals'\n",
    "    elif lex.startswith('more.than') or lex.startswith('no.more.than') or lex.startswith('less.than'):\n",
    "        result = 'cmn'\n",
    "    elif lex.startswith('the.'):\n",
    "        result = 'definites'\n",
    "    elif lex == 'an':\n",
    "        result = 'a'\n",
    "    else:\n",
    "        result = lex\n",
    "    return result\n",
    "\n",
    "\n",
    "def combine_lexicalizations(all_lex_mod):\n",
    "    all_lex_comb = set()\n",
    "    for lex in all_lex_mod:\n",
    "        all_lex_comb.add(assign_group_lex(lex.lower()))\n",
    "    return list(all_lex_comb)\n",
    "\n",
    "        \n",
    "# This funciton is to encode quantifier lexicalisations into a binary feature      \n",
    "def extract_lex(lex, le, nr_r):\n",
    "    colnr = le.transform([lex])[0]\n",
    "    lex_vector = np.zeros((nr_r))\n",
    "    lex_vector[colnr] = 1.\n",
    "    return lex_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2bb3063",
   "metadata": {
    "id": "f2bb3063"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This funciton is to encode grammatical roles and preposition lexicalisation or preposition supersenses into binary features\n",
    "\"\"\"\n",
    "\n",
    "def extract(annot, le, nr_r, opt):\n",
    "    colnr = 999\n",
    "    if opt == 'ss2' and annot[-2].startswith('p.'):\n",
    "        colnr = le.transform([annot[-2]])[0]\n",
    "    elif opt == 'ssss2' and annot[-2].startswith('p.'):\n",
    "        colnr = le.transform([annot[-3] + '_' + annot[-2]])[0]\n",
    "    elif opt == 'prep' and annot[1] not in R_GRAMM:\n",
    "        colnr = le.transform([annot[1]])[0]\n",
    "    elif opt == 'roles' and annot[1] in R_GRAMM:\n",
    "        colnr = le.transform([annot[1]])[0]\n",
    "    \n",
    "    roles_vector = np.zeros((nr_r))\n",
    "    if colnr != 999:\n",
    "        roles_vector[colnr] = 1.  \n",
    "    return roles_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d08777f",
   "metadata": {
    "id": "3d08777f"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function, given certain options e.g. whether to encode preposition lexicalizations or preposition supersenses,\n",
    "returns: a list with feature names, feature vector and a vector of the target variable.\n",
    "\"\"\"\n",
    "def prep_data(data_annotations, data_scopes, roles, quant_lex, prep, super_ss2, super_ssss2):\n",
    "\n",
    "# Create an instance of an encoder of gramamtical roles and take the number of elements in that list\n",
    "    le_roles = preprocessing.LabelEncoder()\n",
    "    le_roles.fit(list(roles))\n",
    "    nr_roles = len(list(roles))\n",
    "    \n",
    "# Set possible label encoders of preposition features to  False. Depending on a condition (e.g. model with preposition\n",
    "# lexicalizations only) those will be later changed to label encoders\n",
    "    le_prep = False\n",
    "    le_super_ss2 = False\n",
    "    le_super_ssss2 = False\n",
    "    \n",
    "# Delete '.appositive' from quantifier lexicalizations list\n",
    "    lex_mod = prep_lex(quant_lex)\n",
    "\n",
    "# Group quantifier lexicalizations\n",
    "    lex_mod_group = combine_lexicalizations(lex_mod)\n",
    "\n",
    "# Create an instance of an encoder of grouped quantifier lexicalizations\n",
    "    le_lex_group = preprocessing.LabelEncoder()\n",
    "    le_lex_group.fit(lex_mod_group)\n",
    "    nr_lex_group = len(lex_mod_group)\n",
    "\n",
    "# Initialize an instance of preposition lexicalizations encoder\n",
    "# Set 'prep' to False if you don't want to include preposition lexicalizations in the experiment\n",
    "    if prep:\n",
    "        if not prep == ALL_PREP:\n",
    "            print('STOP! Something is wrong here!')          \n",
    "        le_prep = preprocessing.LabelEncoder()\n",
    "        le_prep.fit(list(prep))\n",
    "        nr_prep = len(list(prep))\n",
    "\n",
    "# Initialize an instance of preposition supersenses SS2 encoder\n",
    "# Set 'super_ss2' to False if you don't want to include preposition supersenses (SS2) in the experiment\n",
    "    if super_ss2:\n",
    "        if not super_ss2 == ALL_SS2:\n",
    "            print('STOP! Something is wrong here!')\n",
    "        le_super_ss2 = preprocessing.LabelEncoder()\n",
    "        le_super_ss2.fit(list(super_ss2))\n",
    "        nr_super_ss2 = len(list(super_ss2))\n",
    "\n",
    "# Initialize an instance of preposition supersenses SS->SS2 combinations encoder.\n",
    "# Set 'super_ssss2' to False if you don't want to include preposition supersenses (SSSS2) in the experiment\n",
    "    if super_ssss2:\n",
    "        if not super_ssss2 == ALL_SSSS2:\n",
    "            print('STOP! Something is wrong here!')\n",
    "        le_super_ssss2 = preprocessing.LabelEncoder()\n",
    "        le_super_ssss2.fit(list(super_ssss2))\n",
    "        nr_super_ssss2 = len(list(super_ssss2)) \n",
    "\n",
    "\n",
    "# Initilize a list of feature vectors and a list of classes to be predicted\n",
    "    x = []; y = []\n",
    "\n",
    "# Iterate over each sentence's annotation and that sentence's corresponding scope\n",
    "    for scopes, sentence_annotations in zip(data_scopes, data_annotations):\n",
    "# Iterate over each pair of annotations \n",
    "        for s, z in itertools.combinations(sentence_annotations, 2):\n",
    "            \n",
    "# Encode feature COMPLEX\n",
    "            is_comp_1 = is_complex(s[2])\n",
    "            is_comp_2 = is_complex(z[2])\n",
    "\n",
    "# Encode feature APPOSITIVE\n",
    "            app_1 = appositive(s[2])\n",
    "            app_2 = appositive(z[2])\n",
    "\n",
    "# Encode feature DISTANCE. Note that unlike other features, distance in calculated only once since it is \n",
    "# a feature of the relaction between quantifiers in a pair (not a property of each quantifier separately)\n",
    "            dist = distance(sentence_annotations, s, z)\n",
    "\n",
    "# Encode the fourth feature - grammatical roles of a given tag\n",
    "            extr_roles_1 = extract(s, le_roles, nr_roles, 'roles')\n",
    "            extr_roles_2 = extract(z, le_roles, nr_roles, 'roles')\n",
    "\n",
    "# Statements below encode preposition information into feature vectors\n",
    "\n",
    "# Initialie arrays of preposition features (either lexicalizations or supersenses); for BASELINE, for instance, none of\n",
    "# those arrays will be populated.\n",
    "            extr_prep_1 = np.array([])\n",
    "            extr_prep_2 = np.array([])\n",
    "                \n",
    "            extr_super_ss2_1 = np.array([])\n",
    "            extr_super_ss2_2 = np.array([])\n",
    "            \n",
    "            extr_super_ssss2_1 = np.array([])\n",
    "            extr_super_ssss2_2 = np.array([])\n",
    "                \n",
    "# Encode info about preposition lexicalizations\n",
    "            if prep:\n",
    "                extr_prep_1 = extract(s, le_prep, nr_prep, 'prep')\n",
    "                extr_prep_2 = extract(z, le_prep, nr_prep, 'prep')\n",
    "\n",
    "# Encode info about preposition supersenses SS2\n",
    "            if super_ss2:\n",
    "                extr_super_ss2_1 = extract(s, le_super_ss2, nr_super_ss2, 'ss2')\n",
    "                extr_super_ss2_2 = extract(z, le_super_ss2, nr_super_ss2, 'ss2')\n",
    "\n",
    "# Encode info about preposition supersenses SSSS2\n",
    "            if super_ssss2:             \n",
    "                extr_super_ssss2_1 = extract(s, le_super_ssss2, nr_super_ssss2, 'ssss2')\n",
    "                extr_super_ssss2_2 = extract(z, le_super_ssss2, nr_super_ssss2, 'ssss2')\n",
    "\n",
    "# Encode information about grouped quantifier lexicalizations\n",
    "            extr_lex_group_1 = extract_lex(assign_group_lex(del_appositive(s[2])),\n",
    "                                                         le_lex_group, nr_lex_group)\n",
    "            extr_lex_group_2 = extract_lex(assign_group_lex(del_appositive(z[2])),\n",
    "                                                         le_lex_group, nr_lex_group)\n",
    "            \n",
    "# Combine feature vectors into one feature vector          \n",
    "            feature_vector = np.concatenate(([is_comp_1], [app_1], extr_roles_1, extr_lex_group_1,\n",
    "                                             extr_prep_1, extr_super_ss2_1, extr_super_ssss2_1,\n",
    "                                             [dist],\n",
    "                                             [is_comp_2], [app_2], extr_roles_2, extr_lex_group_2, \n",
    "                                             extr_prep_2, extr_super_ss2_2, extr_super_ssss2_2), \n",
    "                                             axis=0)\n",
    "    \n",
    "# Last character of an annotation (e.g. s[-1]) is a letter of the alphabat that identifies each annotation\n",
    "# The scopes are encoded with alphabet letters as well\n",
    "            quantifier_1 = s[-1]\n",
    "            quantifier_2 = z[-1]\n",
    "        \n",
    "# It cannot happen that (label_1, label_2) are not in scopes.keys(); it would mean there is an\n",
    "# error somewhere\n",
    "            if (quantifier_1, quantifier_2) not in scopes.keys():\n",
    "                print('STOP! Something is wrong here!')  \n",
    "            \n",
    "# Extract class label of a given observation and append it to a list\n",
    "            y.append(scopes[(quantifier_1, quantifier_2)])\n",
    "    \n",
    "# Append feature vector of a given observation to a list\n",
    "            x.append(feature_vector)\n",
    "            \n",
    "# Create a list of feature names in the same order in which they appear in the feature vector\n",
    "# This step is necessary for the feature importance analysis\n",
    "    colnames = ['complex_1', 'appositive_1']\n",
    "    for colname in list(le_roles.classes_): colnames.append(colname + '_1')\n",
    "    for colname in list(le_lex_group.classes_): colnames.append(colname + '_1')\n",
    "    if le_prep:\n",
    "        for colname in list(le_prep.classes_): colnames.append(colname + '_1')\n",
    "    if le_super_ss2:\n",
    "        for colname in list(le_super_ss2.classes_): colnames.append(colname + '_1')\n",
    "    if le_super_ssss2:\n",
    "        for colname in list(le_super_ssss2.classes_): colnames.append(colname + '_1')\n",
    "    colnames.append('distance')\n",
    "    colnames.extend(['complex_2', 'appositive_2'])\n",
    "    for colname in list(le_roles.classes_): colnames.append(colname + '_2')\n",
    "    for colname in list(le_lex_group.classes_): colnames.append(colname + '_2')\n",
    "    if le_prep:\n",
    "        for colname in list(le_prep.classes_): colnames.append(colname + '_2')\n",
    "    if le_super_ss2:\n",
    "        for colname in list(le_super_ss2.classes_): colnames.append(colname + '_2')\n",
    "    if le_super_ssss2:\n",
    "        for colname in list(le_super_ssss2.classes_): colnames.append(colname + '_2')\n",
    "            \n",
    "    x = np.array(x) ; y = np.array(y)\n",
    "\n",
    "    return colnames, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e1e14-7bc3-48f0-a34e-eecaacd8f61d",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4f3fac7-c4ff-405e-9f96-9a38686491ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annot_r, train_scope_r, test_annot_r, test_scope_r = split_data(ALL_ANNOTATIONS, ALL_SCOPES, 0)\n",
    "colnames, X_test_r, y_test_r = prep_data(test_annot_r, test_scope_r, ALL_ROLES, ALL_LEX, ALL_PREP, False, False)\n",
    "_, X_train_r, y_train_r = prep_data(train_annot_r, train_scope_r, ALL_ROLES, ALL_LEX, ALL_PREP, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b68972a-aed3-4858-b9a1-651aea43eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7391304347826086\n"
     ]
    }
   ],
   "source": [
    "m1 = svm.SVC()\n",
    "m_fit = m1.fit(X_train_r, y_train_r)\n",
    "pred_test = m_fit.predict(X_test_r)\n",
    "print(accuracy_score(pred_test, y_test_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ccc996-cb40-434e-b23e-edecbb29788f",
   "metadata": {},
   "source": [
    "# Feature importance and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57b8c811-e5ec-4fd2-b080-95ed2fa2eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function returns (saves to a png file) Feature Importance analysis of 18 most relevant features. Corresponds to Figure 3\n",
    "from the paper.\n",
    "\"\"\"\n",
    "\n",
    "def feature_importance(number_feat, file_name, vert):\n",
    "    \n",
    "    cols, d_X, d_y = prep_data(ALL_ANNOTATIONS, ALL_SCOPES, ALL_ROLES, ALL_LEX, ALL_PREP, ALL_SS2, ALL_SSSS2)\n",
    "    \n",
    "    mi_results = mutual_info_classif(d_X, d_y, discrete_features = True)\n",
    "\n",
    "    mi_results_sorted, colnames_sorted = (list(t) for t in zip(*sorted(zip(mi_results, cols), reverse = True)))\n",
    "\n",
    "    cols_sorted_renamed = []\n",
    "    for col in colnames_sorted:\n",
    "        if col.split('_')[0] in ALL_SS2 and len(col.split('_')) < 3:\n",
    "            cols_sorted_renamed.append(col.split('.')[1])\n",
    "        elif len(col.split('_')) > 2 and col.split('_')[0] + '_' + col.split('_')[1] in ALL_SSSS2: \n",
    "            cols_sorted_renamed.append(col.split('_')[0].split('.')[1] + '.' + col.split('_')[1].split('.')[1] + \n",
    "                                     '_' + col.split('_')[2])\n",
    "        elif col.split('_')[0] == 'O':\n",
    "            cols_sorted_renamed.append('object' + '_' + col.split('_')[1])\n",
    "        elif col.split('_')[0] == 'S':\n",
    "            cols_sorted_renamed.append('subject' + '_' + col.split('_')[1])\n",
    "        else:\n",
    "            cols_sorted_renamed.append(col)\n",
    "\n",
    "    if vert:\n",
    "        y_pos = np.arange(len(cols_sorted_renamed))\n",
    "        plt.figure(figsize=(6,6))\n",
    "        #plt.title(figure_name)\n",
    "        plt.yticks(y_pos[:number_feat], cols_sorted_renamed[:number_feat][::-1])\n",
    "        plt.barh(range(len(mi_results_sorted[:number_feat])), mi_results_sorted[:number_feat][::-1], color=\"steelblue\",\n",
    "             align=\"center\")\n",
    "        plt.ylabel('Features')\n",
    "        plt.xlabel('Mutual information')\n",
    "    else:\n",
    "        x_pos = np.arange(len(cols_sorted_renamed))\n",
    "        plt.figure(figsize=(6,6))\n",
    "            #len(colnames_sorted)-number_feat\n",
    "        plt.xticks(x_pos[:number_feat], cols_sorted_renamed[:number_feat], rotation = 45, ha = 'right', fontsize = 12)\n",
    "        plt.bar(range(len(mi_results_sorted[:number_feat])), mi_results_sorted[:number_feat], color=\"steelblue\", align=\"center\")\n",
    "        #plt.xlabel('Features')\n",
    "        plt.ylabel('Mutual Information', fontsize=12)\n",
    "    plt.savefig(file_name, bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b03acb77-42b0-4a39-bbb7-94142b7137c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAFzCAYAAAAADxE8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+X0lEQVR4nO3de5xdZXn28d/FMRBgOPsGEKIYCedoEk6iIKBUaxXa0CighqK8VCgiL1YtVFG0RVRAoAgRORRQUxAVQUEaATEQICdy4GAsYKGkRQQChJJAuN4/1jOy2cye2TOZmb1ncn0/n/nM2s961lr32kO49/Ostdct20RERETrrdHqACIiIqKSpBwREdEmkpQjIiLaRJJyREREm0hSjoiIaBNJyhEREW1irVYHEEPL5ptv7tGjR7c6jIiIIWX27NlP2t6ip35JytEro0ePZtasWa0OIyJiSJH0+2b6Zfo6IiKiTSQpR0REtIkk5YiIiDaRpBwREdEmkpQjIiLaRJJyREREm0hSjoiIaBNJyhEREW0iSTkiIqJNJClHRES0iSTliIiINpGkHBER0SZSkCJ6ZfGSpRx8+g2tDiMiYlDd9I9/PijHyUg5IiKiTSQpR0REtIkk5YiIiDaRpBwREdEmBjQpS9pG0k8lLZb0kKTzJa3bz8fYX9I+Na+PlfSxsjxF0lZN7OMRSZtL2ljSp/ozvppj/FjSITWvH5R0as3rH0n6yxLz+b3c9yOSNu/lNutLukHSA5IWSTqjN9tHRET/G7CkLEnAtcBPbI8BxgDrAWf286H2B/6UlG1faPtfy8spQI9JucbGwIAkZWAGJU5JmwHLgL1r1u8N3DFAx27km7bHAm8D3iHpfYN8/IiIqDGQI+UDgBdtXwpgeyXwGeBjko6vHQ1Kul7S/mX5O5JmldHbl2v6PCLpy5LmSFogaayk0cCxwGckzZP0TkmnSTpZ0iRgAnBVWffnkn5Ss7/3SPpxXcxnANuX/t8o/T4r6R5J8zvjkTS6jDAvk/RbSVdJOkjSjDIrsEcX78cdvPrhYR/gZ8AWqrwJ+F/b/13WbyXpxrKvP32IkfSRcu4LJX29qzdd0pGS7i7ncJGkNbvqZ/sF27eU5RXAHGCbBvs8pvxNZq1YtrSrLhER0Q8GMinvDMyubbD9LPAI3X8/+hTbE4DdgP0k7Vaz7knbbwe+A5xs+xHgQuBs2+Ns315zrGuAWcARtscBPwfGStqidDkKuKTu2J8H/qPs67OS3ks1wt8DGAeMl/Su0vctwLeAseXncGBf4GTgH7o4r9nALpLWoUrKdwIPAjuW17Wj5HHAZGBXYLKkN5Zp+K9TfdgZB0ysnQ4HkLRj2e4d5ZxXAkd0EctrSNoY+AtgelfrbU+1PcH2hHVGdvS0u4iI6KN2vNHrryXNAeZSJfadatZdW37PBkb3Zqe2DVwBHFmS0N7AL3rY7L3lZy7VSHIsVZIGeNj2AtuvAIuA6eUYC7qKzfby0u/twF7AXVSJeZ/yM6Om+3TbS22/CNwHbAdMBG61/QfbLwNXAe/itQ4ExgP3SJpXXr+5uxOUtBbwA+Bc2w/18H5ERMQAGsgnet0HTKptkLQR8H+APwJvrVk1oqx/E9VIc6LtpyVd1rmuWF5+r6RvsV9KNW38InB1SW7dEfDPti+qO4/RNbEAvFLz+pVuYptBlUg3LOc3Ezie6ppu7TFq992bcxVwue0vNNkfYCqw2PY5vdgmIiIGwECOlKcD69fcCb0m1XTv+cDDwDhJa0h6I9X0MMBGVDdALZX0BqCZG4+eAzZsZp3tx4HHgVOpEnRP+7oJ+BtJG5Rz2FrSlk3E1MgdwP8F7i2v51ONmrcFFvaw7d1U0/mbl/fyI8BtdX2mA5M6Y5S0qaTtGu1Q0leBDuDEXp5HREQMgAFLymUq91CqJLGYanT8iu2vUY0YH6YaTZ9LNTWM7XuppoofAL7Pa6d0G/kZcGjnjV516y4DLizr1ittVwGP2r6/i5j/CMwoN1J9w/YvSxx3SloAXEPjDwCvI2mCpItrmu6gmk6+sxzvZeAJYFaZBm/I9hKqa963UCX12bZ/WtfnPqoPHL+UNB+4GRjVILZtgFOoLg/MKe/RJ5o9t4iI6H+qcucgHKj6LvEPgENtzxmUg3Ydx/nAXNvfa1UMQ1nH1mO817HntDqMiIhBtaoFKSTNLjcxd99vsJJyO5A0m2p6/D3lxqvopQkTJnjWrFmtDiMiYkhpNimvVqUbbY9vdQytIOkuoP5Jah+1vaAV8URERNdWq6S8urK9Z6tjiIiIniUpR68sXrKUg0+/odVhRES8xqpe820X7fjwkIiIiNVSknJERESbSFKOiIhoE0nKg0TS2ZJOrHl9U+2DRSR9S9JJkq7v5X5vldTjbfZdbHeVqprOCyVdImnt3u4jIiL6V5Ly4Kmtp7wGsDlVwY1O+wDrDGI8V1EV2NiVqs51nuYVEdFiScqD5w6qylRQJeOFwHOSNpG0LlUJxznABpKuKfWar5IkAEkHSppb6ilfUrZ5DUnvlXSnqprTV3c+s7srtn/uguq52l3WUo6IiMGTpDxISjGMlyVty6v1lO+iStQTqEo+rqCqGHUi1TOp3wy8Q9IIqud4T7a9K9VX2f62dv+SNqd67vVBpeb0LOCknuIq09YfBW7sps8xkmZJmrVi2dJenHVERPRGkvLguoNX6yffSdf1lO+2/VgpUDGPqjbzDlT1m39b+lzO62sp70WVyGeUWsofp6rD3JMLgF/bvr1RB9tTbU+wPWGdkR1N7DIiIvoiDw8ZXJ3XlXelmr5+FPh/wLO8WkpyVWop32z7I80GI+lLwBZU5SQjIqLFMlIeXHcAHwCesr3S9lPAxlRT2Hd0s92DwGhJbymvP8rraynPpJrqfguApJGS3tpoh6VM48HAR3oqGxkREYMjSXlwLaC663pmXdtS20822sj2i8BRwNWlrvMrwIV1ff4ATAF+UGop30l1d3UjFwJvoKoVPU/SF3t/OhER0Z8yfT2IbK8ENqprm1KzfCtwa83r42uWp1PdBFa/z/1rln8FTGwylvztIyLaTP7HHL0yZlTHsHnwe0REu0lSHuYk/Rh4U13z52zf1Ip4IiKisSTlYc72oa2OISIimpMbvSIiItpERsrRK4uXLOXg029odRgRbSf3WkR/yEg5IiKiTSQpR0REtIkk5YiIiDaRpDxMSTpB0v2Srmqw/ghJ80spyDsk7T7YMUZExGvlRq/h61NUZRwfa7D+YWA/209Leh8wFdhz0KKLiIjXyUh5GJB0kqSF5edESRdS1WL+haTPdLWN7TtsP11ezgS26Wb/qaccETEIMlIe4iSNpypWsSdV+ca7gCOBPwPe3V2hixpHA79otNL2VKqRNB1bj/GqxhwREV1LUh769gV+bHsZgKRrgXc2u7Gkd1Ml5X0HJryIiGhWkvJqTNJuwMXA+2z/sdXxRESs7nJNeei7HThE0vqSRgKHlrZuSdoWuBb4qO3fDnCMERHRhIyUhzjbcyRdBtxdmi62PVdST5t+EdgMuKD0fdn2hAELNCIiepSkPAzYPgs4q65tdA/bfAL4xACGFRERvZSkHL0yZlRHHrwfETFAkpSHOUlHAZ+ua55h+7hWxBMREY0lKQ9zti8FLm11HBER0bMk5eiV1FNefeQyRcTgy1eiIiIi2kSSckRERJtIUo6IiGgTuabcQpJOA54HNgJ+bfvfG/Q7BPit7fsGL7qIiBhsGSm3AdtfbJSQi0OAnQYpnIiIaJEk5UEm6RRJv5X0G2CH0naZpEll+QxJ90maL+mbkvYBPgh8Q9I8SdtL+qSkeyTdK+lHktav2c+5ku6Q9FDnPsu6z0laULY5o7RtL+lGSbMl3S5p7KC/IRER8SeZvh5Epfbxh4FxVO/9HGB2zfrNqApKjLVtSRvbfkbSdcD1tq8p/Z6x/d2y/FWq0ovnld2MoirDOBa4DrhG0vuADwF72n5B0qal71TgWNuLJe0JXAAc0EXcxwDHAIzo2KLf3o+IiHitJOXB9U6q2scvAJRkW2sp8CLwPUnXA9c32M8uJRlvDGwA3FSz7ie2XwHuk/SG0nYQcGnncW0/JWkDYB/g6priFet2dTDbU6kSOB1bj3GT5xoREb2UpNxGbL8saQ/gQGAScDxdjFyBy4BDbN8raQqwf8265TXL3ZWKWgN4xva4VQg5IiL6Ua4pD65fU9U+Xk/ShsBf1K4so9cO2z8HPgPsXlY9B2xY03VDYImktYEjmjjuzcBRNdeeN7X9LPCwpMNKmyTt3t1OIiJiYCUpDyLbc4BpwL3AL4B76rpsCFwvaT7wG+Ck0v5D4LOS5kraHvhH4C5gBvBAE8e9ker68ixJ84CTy6ojgKMl3QssorruHBERLSI7lwijeR1bj/Fex57T6jBiEOTZ1xH9R9Js2xN66peRckRERJvIjV7RK2NGdWQEFRExQDJSjoiIaBNJyhEREW0i09fRK4uXLOXg029odRjRR7n0ENHeMlKOiIhoE0nKERERbSJJOSIiok0Mm6QsabSkha2Oo1Vqyz/2YpuTaspETpe03UDFFxERPRs2SXlVSBoSN7xJWrOfdzkXmGB7N+Aa4Mx+3n9ERPTCcEvKa0m6StL9kq6RtL6kL0q6R9JCSVNV6hRKulXSOZJmAZ+WNF7SbZJmS7pJ0qj6nUs6TdIlZduHJJ1Q2l8zSpd0sqTTao5ztqRZJa6Jkq6VtLiUX+zc5khJd0uaJ+mizgQs6XlJ3yrPp9670fnUxXlGzQj4m43eLNu3dJZzBGYC2/ThPY+IiH4y3JLyDsAFtncEngU+BZxve6LtXYD1gA/U9F+nPIv0XOA8YJLt8cAlwNcaHGMscDCwB/ClUqmpJyvKcS4EfgocB+wCTJG0maQdgcnAO0opxZW8Wv1pJHCX7d1t/6aH80HSZsChwM5lBPxVmnM0VZGM15F0TPlQMWvFsqVN7i4iInprSEzb9sKjtmeU5SuBE6jKE/49sD6wKVU1pJ+VPtPK7x2okuTNZeC5JrCkwTFusL0cWC7pCeANTcR1Xfm9AFhkewmApIeANwL7AuOBe8rx1wOeKNusBH5Us693d3M+AEuBF4HvSboeuL6n4CQdCUwA9utqve2pwFSoClL0tL+IiOib4ZaU6xOGgQuorps+WqaUR9SsX1Z+iypZ7t3EMZbXLK+keg9f5rWzDiN4rc5tXqnb/pWyvYDLbX+hi+O9aHslgKQRPZwPtl+WtAdwIDAJOB44oNHJSDoIOAXYr3zYiIiIFhlu09fbSupMrIdT1SQGeFLSBlRJqisPAlt0bitpbUk79+K4/wNsWaai16VuSrkJ04FJkrYsx9+0wZ3QnQm44fmU9g7bPwc+A+ze6KCS3gZcBHzQ9hON+kVExOAYbiPlB4HjJF0C3Ad8B9gEWAj8N3BPVxvZXlG+TnSupA6q9+UcYJGkY0ufCxsd1PZLkr4C3A38F/BAb4K2fZ+kU4FfSloDeInquvPv6/o9I+m7PZzPhsBPy6hawEndHPobwAbA1WXa/D9tf7A3sUdERP+RnUuE0byOrcd4r2PPaXUY0Ud59nVEa0iaXW747dZwGynHAEs95YiIgZOkvBqQdApwWF3z1bYbfe0rIiJaIEl5NVCSbxJwRESbG253X0dERAxZGSlHryxespSDT7+h1WGs9nJdP2J4ykg5IiKiTSQpR0REtIkk5YiIiDaRpNxGJG0l6ZqyPE7S+2vWfVDS5/vxWCfVlHec3uCxnhERMYiSlNuI7cdtdz7Pehzw/pp119k+ox8PN5eqsMVuwDXAmf2474iI6IMk5W5I+omk2ZIWSTqmtD0v6ezSNl3SFqX9VknfljRP0sJSqamzuMRPyoh0pqTdSvt+pe88SXMlbShpdNl2HeArwOSyfrKkKZLOl9Qh6fflGdlIGinp0VJEY3tJN5aYb5c0ttG52b7F9gvl5Uxgm27eh9RTjogYBEnK3fsb2+Opag2fIGkzYCQwy/bOwG3Al2r6r297HPAp4JLS9mVgbhmR/gPwr6X9ZOC40v+dwP927sT2CuCLwDTb42xPq1m3FJjHq7WPPwDcZPslqprHf1diPpmqzGMzjgZ+0Wil7am2J9iesM7IjiZ3GRERvZXvKXfvBEmHluU3AmOoaiB3JskrgWtr+v8AwPavJW0kaWNgX+CvSvuvSnnHjYAZwFmSrgKutf1YqdTUjGnAZOAW4MPABaVk4z68WvEJYN2ediTpSKoPHfv11DciIgZWknIDkvYHDgL2tv2CpFt5tZ5xLTdY7ur1qyvsMyTdQHXdeIakg4EXmwzvOuCfJG0KjAd+RTWCf6aMvJsi6SDgFGA/28ub3S4iIgZGpq8b6wCeLgl5LLBXaV8D6LwZ63DgNzXbTAaQtC+wtEw13w4cUdr3B560/ayk7W0vsP11qrrI9dd/n6Oqjfw6tp8v23wbuN72StvPAg9LOqwcS5J2b3Rykt4GXAR80PYTPb4bEREx4JKUG7sRWEvS/cAZVDdDASwD9pC0EDiA6oasTi9KmgtcSHWdFuA0YLyk+WU/Hy/tJ5abuuYDL/H6a7q3ADt13ujVRXzTgCN5dSodquR/tKR7gUXAh7o5v28AG1BNd8+TdF03fSMiYhDIbjjDGl2Q9LztDbpovxU42faswY9q8HRsPcZ7HXtOq8NY7eXZ1xFDi6TZtif01C/XlKNXxozqSEKIiBggScq91NUoubTvP8ihNEXSKcBhdc1XlxrLERHRRpKUh7mSfJOAIyKGgCTl6JXUU26tXDqIGN5y93VERESbSFKOiIhoE0nKERERbSJJOSIiok2sdklZ0iGSdqp5fZmkSd1t0+4k7S/p+l5uM07SnaUE5fwGTw2LiIhBtNolZeAQYKeeOrUbSf19p/wLwMdKCco/A84pVa0iIqJF2jYpSzpS0t3lucwXSdqzjOhGSBpZRni7SNpA0nRJcyQtkPShmn18rGxzr6QrJO0DfBD4Rtnv9jV9D5D0k5rX75H045rXoyXdL+m75di/lLReWXerpAlleXNJj5TlKZJ+IulmSY9IOl7SSZLmSppZqjwhaXtJN0qaLen2UgCjcxR/oaS7gDMl7VFGt3Ml3SFphy7et/3Kuc0r/RoVtfit7cVl+XHgCWCLBn+LYyTNkjRrxbKlTf39IiKi99rye8qSdqSquPQO2y9JugDYgapk4VeB9YArbS8sI8hDS+WlzYGZpbjCTsCpwD62n5S0qe2nyrrrbV9TjtV52Fuo6hJvYfsPwFHAJXWhjQE+YvuTkv6Nqk7ylT2czi7A26jKPv4O+Jztt0k6G/gYcA4wFTjW9mJJewIXUBW7ANimnMNKVXWY32n75VJ28Z9KDLVOBo6zPUNVjeUey0FK2gNYB/iPrtbbnlpipGPrMXlYekTEAGnLpAwcSFUn+J6SNNejGsl9hapk4YvACaWvqGoLvwt4BdgaeANVUrva9pMAtp/q7oC2LekK4EhJlwJ7UyXNWg/bnleWZwOjmziXW2w/BzwnaSnws9K+ANitJM59qKo1dW6zbs32V9teWZY7gMsljaGq1bx2F8ebAZwl6SrgWtuPdRecpFHAFcDHbb/SxPlERMQAadekLOBy2194TWOVQDagSkYjqMooHkE17Tq+jKofKev64lKqpPkiVTJ8uW798prllVQfFgBe5tVLAfXHrt3mlZrXr1C9/2sAz9ge1yCmZTXLp1Ml+UMljQZure9s+wxJNwDvB2ZIOtj2A13tuIy8bwBOsT2zqz4RETF42vWa8nRgkqQtASRtKmk74CLgH4GrgK+Xvh3AEyUhvxvYrrT/CjhM0mad+yjtzwGNrrM+DjxONe19aS/ifYRqZA/Qqzu5bT8LPCzpsBKnJO3eoHsH8F9leUpXHSRtb3uB7a9TzSqMbdBvHeDHwL92TuVHRERrtWVStn0fVWL8paT5wM3Ax4GXbH8fOAOYKOkAqgQ9QdICqunmB8o+FlEVYrhN0r3AWWX3PwQ+W26C2p7Xuwp41Pb9kraS9PMmQv4m8LeS5gKb9+GUjwCOLnEuAj7UoN+ZwD+X4zSa5ThR0sLyvr0E/KJBv78G3gVMqbkxbFwfYo+IiH4iO/ft1JJ0PjDX9vdaHUs76th6jPc69pxWh7HaSkGKiKFJ0mzbE3rq167XlFtC0myqa7j/r9WxtKsxozqSGCIiBkiScg3b43vuNbRI2pXq7upay23v2Yp4IiKisSTlYc72AmBcq+OIiIieJSlHryxespSDT7+h1WGsNnKpIGL10pZ3X0dERKyOkpQjIiLaRJJyREREm0hSbrFSfWphg3UXq6b2cy/2OU7S+3voc0SpoLWgVJxq9BSxiIgYJLnRq43Z/kQfNx0HTAC6exrZw8B+tp+W9D6qKlD5mlRERAtlpDzISj3lheXnxNK8lqSrSr3mayStX/rW1ml+b6mlPEfS1aW6FJImlpHuvarqT3dQVdOaXB6dObmrOGzfYfvp8nImVYnIiIhooSTlQSRpPFWd5j2BvYBPAptQ1Yq+wPaOwLPAp+q225zqWeAH2X47MAs4qRSVmAZ82vbuwEFUTyT7IjDN9jjb05oI7WgaPyMbScdImiVp1oplS3t1zhER0bwk5cG1L/Bj28tsPw9cC7yTqgDGjNLnytKv1l7ATlSlGOdRFefYjiqZL7F9D1QVp7ooN9mtUlnraOBzjfrYnmp7gu0J64zs6M3uIyKiF3JNuT3UVwWpfy3gZtsfeU1j9QjNPpO0G3Ax8D7bf1yVfUVExKrLSHlw3Q4cIml9SSOBQ0vbtpL2Ln0OB35Tt91M4B2S3gIgaaSktwIPAqMkTSztG0pai25qRneStC3VSP2jtn/bP6cXERGrIkl5ENmeA1wG3A3cRTVKfZoquR4n6X6qa8zfee1m/gMwBfhBqZN8JzDW9gpgMnBeqcV8MzACuAXYqbsbvaiuO28GXFD6zerXk42IiF7L9PUgs30WcFZd89gG3TcDnirb/QqY2MX+7qG65lzvdX3rtvsE0NevXEVExABoKilL2h54zPZySfsDuwH/avuZgQtt9SbpZmCB7YdbHUut1FOOiBg4zU5f/whYWa5pTgXeCHx/wKIKbL/H9uGruh9JR5Xp6dqff+mPGCMion81O339iu2XJR0KnGf7PElzBzKw6B+2LwUubXUcERHRs2ZHyi9J+gjV92OvL21rD0xIERERq6dmR8pHAccCX7P9sKQ3AVcMXFjRrhYvWcrBp9/Q6jCGpVyrj4imkrLt+yR9Dti2vH4Y+PpABhYREbG6aWr6WtJfAPOAG8vrcZKuG8C4IiIiVjvNXlM+DdgDeAbA9jzgzQMSUURExGqq6Ru9bNeXB3qlv4OJ7km6TNKkftzf1yQ9Kun5/tpnRET0XbNJeZGkw4E1JY2RdB5wxwDGFYPjZ1QzIBER0QaaTcp/B+wMLKd6aMhS4MQBimnIkfQxSfMl3SvpCkmjJf2qtE0vxR86R7rfkTRT0kOS9pd0iaT7JV1Ws7/nJZ0taVHZfosujjle0m2SZku6SdIoSR2SHpS0Q+nzA0mfbBS37Zm2lzRxfqmnHBExCHpMypLWBG6wfYrtieXnVNsvDkJ8bU/SzsCpwAG2dwc+DZwHXG57N+Aq4NyaTTYB9gY+A1wHnE31gWdXSeNKn5HALNs7A7cBX6o75trlGJNsjwcuofq62lLgeOAySR8GNrH93VU9x9RTjogYHD1+Jcr2SkmvSOro4rpywAHA1bafBLD9VCnD+Jdl/RXAmTX9f2bbkhYA/2N7AYCkRcBoqrvcXwGmlf5XUpVYrLUDsAtwsySANYEl5fg3SzoM+Bdg9/47zYiIGGjNPjzkeWBBKZKwrLPR9gkDEtXwtrz8fqVmufN1o7+H614LWGR77/qOktYAdgReoBqVP7ZK0UZExKBp9prytcA/Ar8GZtf8BPwKOEzSZgCSNqW6Ce7DZf0RwO293OcaQOdd1ocDv6lb/yCwRRmRI2ntMo0O1bT4/WW7S8tUd0REDAHNPtHr8oEOZKiyvUjS14DbJK0E5lLdGHeppM8Cf6B6TGlvLAP2kHQq8AQwue6YK8pXo86V1EH1dzxH0stUNZL3sP2cpF9TXe/+El2QdCZV8l5f0mPAxbZP62WsERHRT2TXz4x20Ul6mNdPoWI7DxAZAJKet71Bq+PoSsfWY7zXsee0OoxhKc++jhi+JM22PaGnfs1eU67d0QjgMGDTvgQWQ9uYUR1JHhERA6TZ6es/1jWdI2k28MX+Dyn6e5Qs6S5g3brmj3be+R0REe2hqaQs6e01L9egGjk3O8qOFrO9Z6tjiIiInjWbWL9Vs/wy8DDw1/0fTrS71FPum0z5R0Qzmk3KR9t+qLZB0psGIJ6IiIjVVrPfU76mybaIiIjoo25HypLGUj2XuUPSX9as2ojqLuyIiIjoJz1NX+8AfADYGPiLmvbngIbVhyIiIqL3uk3Ktn8K/FTS3rbvHKSYooFS3vF626t86UDS+sDVwPbASqpCGZ9f1f1GRETfNXuj11xJx1FNZf9p2tr23wxIVDFYvmn7FknrANMlvc/2L1odVETE6qrZG72uAP4PcDBVfd9tqKawA5D0MUnzJd0r6QpJoyX9qrRNl7Rt6XeZpO9IminpIUn7S7pE0v1lFNy5v+clnS1pUdl+iy6OOV7SbZJmS7pJ0ihJHZIelLRD6fMDSV1eZrD9gu1byvIKYA7V37Wr8ztG0ixJs1YsS/XOiIiB0mxSfovtfwSWleIUfw7kgRRAqc50KnCA7d2BTwPnAZfb3g24Cji3ZpNNgL2pqjldB5xNNQOxq6Rxpc9IYJbtnak+BL2moESp/HQeMMn2eOAS4Gul3vXxwGWSPgxsYvu7TZzDxlT3DEzvar3tqbYn2J6wzsiOnnYXERF91Oz09Uvl9zOSdgH+G9hyYEIacg4Arrb9JIDtp0pJxc671a8Azqzp/zPblrQA+J/OR11KWgSMBuZR1VaeVvpfSVU6s9YOwC7AzZIA1gSWlOPfLOkw4F+A3XsKXtJawA+Ac+u/ix4REYOr2aQ8VdImVDWVrwM2IM+97qvl5fcrNcudrxv9PeordAlYZHvv+o6S1gB2BF6gGpU/1kM8U4HFts/poV9ERAywpqavbV9s+2nbt9l+s+0tbV840MENEb8CDpO0GYCkTYE7gA+X9UcAt/dyn2sAk8ry4cBv6tY/CGxRRuRIWrtMo0M1LX5/2e7SMtXdJUlfBTqAE3sZX0REDIBmC1K8AfgnYCvb75O0E7C37e8NaHRDgO1Fkr4G3CZpJTAX+DuqhPhZ4A/AUb3c7TJgD0mnAk8Ak+uOuULSJOBcSR1Uf8dzJL0MfALYw/Zzkn5Ndb37S9SRtA1wCvAAMKdMg59v++JexhoREf1Edv3MaBedpF8AlwKn2N69XIeca3vXgQ5wdSTp+f4u39hfOrYe472OPafVYQw5KUgRsXqTNNv2hJ76NXtNeXPb/ybpCwC2Xy6jwljNjBnVkQQTETFAmk3Ky8o1UwNI2gvIF1YHSH+PkiXdBaxb1/zRzju/IyKiPTSblE+iuut6e0kzgC149UakaHO2853yiIghoKcqUdva/k/bcyTtR/X9WAEP2n6pu21jeFq8ZCkHn35Dq8NoqUzfR8RA6ekrUT+pWZ5me5HthUnIERER/a+npKya5TcPZCARERGru56SshssR0RERD/rKSnvLulZSc8Bu5XlZyU9J+nZwQiwv0k6pDz8pPP1ZeVBHENWqTZ1fR+2u1HSM33ZNiIi+l+3N3rZXnOwAhlEhwDXA/e1OI5ekbSW7Zf7ebffANYH/m8/7zciIvqg2dKNg07SkZLuljRP0kWS9iz1iUdIGllqDe8iaYNSc3iOpAWSPlSzj/o6x/sAHwS+Ufa7fU3fAyT9pOb1eyT9uOb16FL3+Lvl2L+UtF5Zd6ukCWV5c0mPlOUpkn4i6WZJj0g6XtJJkuaqqqm8aem3fRm1zpZ0u6Sxpf0ySReW7xmfKWkPSXeW7e/orJtc977tV85tXum3YaP32PZ0Uhc7IqJtNPs95UElaUeq5z2/w/ZLki6g+jrWdcBXgfWAK20vLI/8PNT2s5I2B2ZKug7Yieq5z/vYflLSpqWs4nXA9bavKcfqPOwtwAWStrDd+bzqS+pCGwN8xPYnJf0b8FdUpRW7swvwNmAE8Dvgc7bfJuls4GPAOVSVmo61vVjSnsAFVCUhAbYp57BS0kbAO8sT1Q6ieh75X9Ud72TgONszJG0AvNhDfD2SdAxwDMCIji1WdXcREdFAWyZl4EBgPHBPSZrrURVm+ApwD1WiOaH0FfBPkt5FVf5wa+ANdFHnuLsDlhrHVwBHSroU2JsqadZ62Pa8sjybqv5xT26x/RzwnKSlwM9K+wKq6/QbAPsAV9d8QKh9+tbVtjsfadoBXC5pDNWNd11VgJoBnCXpKuBa2z2VbuyR7alUHxzo2HpMbviLiBgg7ZqUBVxu+wuvaZRGUdVyXptq5LmMqjTiFsD4Mqp+pKzri0upkuaLVMmw/hpubf3jlVQfFgBe5tVLAfXHrq+ZXFtPea2y3TO2xzWIaVnN8ulUSf5QSaOBW+s72z5D0g3A+4EZkg62/UCDfUdERBtp12vK04FJkraEqkaxpO2Ai4B/BK4Cvl76dgBPlIT8bmC70t5VnWOorqF2eZ3V9uPA41TT3pf2It5HqEb20MvHj9p+FnhY0mElTknavUH3DuC/yvKUrjpI2t72Attfp5pVGNubeCIionXaMinbvo8qMf5S0nzgZuDjwEu2vw+cAUyUdABVgp4gaQHVdPMDZR+LgM46x/cCZ5Xd/xD4bLkJante7yrgUdv3S9pK0s+bCPmbwN9Kmgts3odTPgI4usS5CPhQg35nAv9cjtNoluNESQvL+/YS8ItGB5V0O3A1cKCkxyQd3IfYIyKinzRVT3l1Iul8qlrR32t1LO0o9ZTz7OuI6D31cz3l1YKk2VTXcP9fq2NpV6mnHBExcJKUa9ge33OvoUXSrsAVdc3LU84xIqL9JCkPc7YXAONaHUdERPSsLW/0ioiIWB1lpBy9snjJUg4+/YZWh9ESuZYeEQMtI+WIiIg2kaQcERHRJpKUIyIi2kSSchuQdJqkk7to30rSNX3c5xRJW/XQ53hJv5PkUmErIiJaKEm5jdl+3HavnqVdYwrQbVKmqih1EPD7Ph4jIiL6UZLyAJE0UtINku4tz6KeLOmRzhGppAmSbq3ZZHdJd0paLOmTpc9oSQvL8pqSviHpHknzJf3fmmN9TtKCcqwzJE0CJgBXSZonaT26YHuu7UeaOJdjJM2SNGvFsqV9fk8iIqJ7+UrUwPkz4HHbfw4gqYNXK1t1ZTdgL2AkMLeUX6x1NLDU9kRJ61KVZfwlVRWoDwF72n5B0qa2n5J0PHCy7VmreiKppxwRMTgyUh44C4D3SPq6pHfa7mmI+VPb/2v7SeAWYI+69e8FPiZpHnAXsBkwhmr6+VLbLwDYfqo/TyIiIgZPRsoDxPZvJb0deD/wVUnTgZd59YPQiPpNengt4O9s3/SaxpRbjIgYNjJSHiDlzucXbF8JfAN4O/AI0Fn04q/qNvmQpBGSNgP2B+6pW38TVc3mtcv+3yppJFWt6aMkrV/aNy39nwM27NeTioiIAZWkPHB2Be4u081fAr4KfBn4tqRZwMq6/vOppq1nAqfbfry0d46YLwbuA+aUm78uAtayfSNwHTCrHKvzq1WXARd2d6OXpBMkPQZsA8yXdPGqnXJERKwK2blvp11JGg+cZXu/VsfSqWPrMd7r2HNaHUZL5NnXEdFXkmbbntBTv1xTblOSJgDfBz7f6lhqjRnVkeQUETFAkpTbVPkq01v7Y1+Sfgy8qa75c/U3jUVERGslKa8GbB/a6hgiIqJnScrRK8OxnnKm4yOiXeTu64iIiDaRpBwREdEmkpQjIiLaxLBJyrUVlVZHki4r1aF6s827JM2R9HJvt42IiP43bJLyqpA0JG54k7RmP+/yP6nqLn+/n/cbERF9MNyS8lqSrpJ0v6RrJK0v6YulBvFCSVMlCUDSrZLOKY+8/LSk8ZJukzRb0k2SRtXvXNJpki4p2z4k6YTS/ppRuqSTJZ1Wc5yzSz3i+yVNlHRtqZv81ZptjpR0d3ks5kWdCVjS85K+JeleYO9G51MX5xmS7it1l7/Z6M2y/Yjt+cArfX3DIyKi/wy3pLwDcIHtHYFngU8B59ueaHsXYD3gAzX91ymPPTsXOA+YZHs8cAnwtQbHGAscTFVa8UudBSJ6sKIc50Lgp8BxwC7AFEmbSdoRmAy8w/Y4qudiH1G2HQncZXt327/p4XwoBS0OBXa2vRvVM7dXiaRjyoeKWSuW9VSBMiIi+mpITNv2wqO2Z5TlK4ETgIcl/T2wPrApsAj4WekzrfzegSpJ3lwGnmsCSxoc4wbby4Hlkp4A3tBEXNeV3wuARbaXAEh6CHgjsC9V9ah7yvHXA54o26wEflSzr3d3cz4AS4EXge9Juh64von4umV7KjAVqmdfr+r+IiKia8MtKXdVk/gCYILtR8uUcm0d42Xlt6iS5d5NHGN5zfJKqvewtk4yvL5Wcuc2r9Rt/0rZXsDltr/QxfFetL0SQNKIHs4H2y9L2gM4EJgEHA8c0MR5RUREiw236ettJXUm1sOB35TlJyVtQJWkuvIgsEXntpLWlrRzL477P8CWZSp6XeqmlJswHZgkacty/E0lbddFv84E3PB8SnuH7Z8DnwF272UsERHRIsNtpPwgcJykS6hqD38H2ARYCPw3cE9XG9leUb4SdK6kDqr35RxgkaRjS58LGx3U9kuSvgLcDfwX8EBvgrZ9n6RTgV9KWgN4ieq68+/r+j0j6bs9nM+GwE/LqFrASY2OK2ki8GOq9+gvJH3Zdm8+jERERD9KPeXoleFYTznPvo6IgdZsPeXhNn0dERExZA236evogqRTgMPqmq+23ehrXw2NGdWRkWVExABJUl4NlOTb6wQcERGDK9PXERERbSIj5eiVxUuWcvDpN7Q6jFWWKfiIaEcZKUdERLSJJOWIiIg2kaQcERHRJpKUV2OSvibpUUnPtzqWiIhIUl7d/YyqBGVERLSBJOVhSNJPJM2WtEjSMY362Z7ZWUYyIiJaL1+JGp7+xvZTktajqtH8I9t/7OvOSmI/BmBExxb9FWNERNTJSHl4OkHSvcBM4I3AmFXZme2ptifYnrDOyI5+CTAiIl4vI+VhRtL+wEHA3rZfkHQrr9ZhjoiINpaR8vDTATxdEvJYYK9WBxQREc1JUh5+bgTWknQ/cAbVFHaXJJ0p6TFgfUmPSTptkGKMiIguZPp6mLG9HHhfk33/Hvj7gY0oIiKalaQcvZJ6yhERAydJeTUg6S5g3brmj9pe0Ip4IiKia0nKqwHbe7Y6hoiI6Flu9IqIiGgTGSlHryxespSDT7+h1WH0Wa6HR0Q7y0g5IiKiTSQpR0REtIkk5YiIiDaRpNxikkZLWthg3cWSdurDPsdJen8PfcZKulPSckkn9/YYERHR/3KjVxuz/Yk+bjoOmAD8vJs+TwEnAIf08RgREdHPMlIeZJJOkrSw/JxYmteSdJWk+yVdI2n90vdWSRPK8nvLyHaOpKslbVDaJ0q6Q9K9ku6W1AF8BZgsaZ6kyV3FYfsJ2/cALzUR8zGSZkmatWLZ0n54FyIioitJyoNI0njgKGBPqupNnwQ2AXYALrC9I/As8Km67TYHTgUOsv12YBZwkqR1gGnAp23vTlWycRnwRWCa7XG2p61q3KmnHBExOJKUB9e+wI9tL7P9PHAt8E7gUdszSp8rS79aewE7ATMkzQM+DmxHlcyXlBEvtp+1/fLAn0ZERAyEXFNuD+7htYCbbX/kNY3SrgMaVUREDKqMlAfX7cAhktaXNBI4tLRtK2nv0udw4Dd1280E3iHpLQCSRkp6K/AgMErSxNK+oaS1gOeADQf+dCIioj8lKQ8i23OAy4C7gbuAi4GnqZLrcZLup7rG/J3XbuY/AFOAH0iaD9wJjLW9ApgMnCfpXuBmYARwC7BTdzd6Sfo/kh4DTgJOlfSYpI36+5wjIqJ5mb4eZLbPAs6qax7boPtmVF9dwvavgIld7O8eqmvO9V7Xt267/wa26SneiIgYPEnKbUrSzcAC2w+3OpZaY0Z1pKhDRMQASVJuU7bf0x/7kXQU8Om65hm2j+uP/UdERP9JUh7mbF8KXNrqOCIiomdJytErQ62ecqbaI2Ioyd3XERERbSJJOSIiok0kKUdERLSJJOVhRNIUSec32Xd9STdIekDSIklnDHR8ERHRvSTl1ds3bY8F3kb1GM/3tTqgiIjVWZJyG5F0ZKmJPE/SRZLWlPSdUst4kaQv1/Str6Pc+azrrSTdKGmxpDMbHcv2C7ZvKcsrgDnkCV8RES2Vr0S1CUk7Uj3H+h22X5J0AXAEcIrtpyStCUyXtBvwAFUd5cm27ynPrP7fsqtxVCPf5cCDks6z/WgPx94Y+Avg2w3WHwMcAzCiY4tVO9GIiGgoSbl9HAiMB+6RBLAe8ATw1yUprgWMoqqrbOrqKAOU7abbXlpe30dVd7lhUi5VpX4AnGv7oa762J4KTAXo2HpMfVnJiIjoJ0nK7UPA5ba/8KcG6U1UlZ8m2n5a0mVUVaC6s7xmeSU9/42nAottn9PriCMiol/lmnL7mA5MkrQlgKRNgW2BZcBSSW8AOm/EalRHuVckfRXoAE5c9fAjImJVZaTcJmzfJ+lU4JeS1gBeAo4D5lJdQ34UmFH6rih1ks+TtB7V9eSDenM8SdsAp5R9zylT3+fbvrifTikiInopSbmN2J5GdQNXrZkN+nZVR/my8tPZ5wPdHOsxqinziIhoE5m+joiIaBMZKa8GJN0FrFvX/FHbC3q7rzGjOlJ5KSJigCQprwZs79nqGCIiomeZvo6IiGgTGSlHryxespSDT7+h1WE0JdPsETHUZKQcERHRJpKUIyIi2kSSckRERJtIUh5GJE2RdH4v+n9N0qOSnh/IuCIiojlJyqu3nwF7tDqIiIioJCm3EUlHSrpb0jxJF0laU9J3JM2StEjSl2v6TpR0h6R7yzYbllVbSbpR0mJJZ3Z3PNszbS8Z0JOKiIim5StRbULSjsBk4B22X5J0AXAEcIrtpyStCUyXtBtVEYlpwGTb90jaiKooBcA44G1UJRwflHSe7Yb1lJuM7RjgGIARHVusyq4iIqIbScrt40BgPHBPqdi0HvAE8NclKa4FjAJ2AgwsKUUpsP0sQNluuu2l5fV9wHZUFab6zPZUqrrLdGw9xquyr4iIaCxJuX0IuNz2F/7UIL0JuBmYaPtpSZcBI3rYz/Ka5ZXkbxwRMWTkmnL7mA5MkrQlgKRNgW2BZcBSSW8A3lf6PgiMkjSx9N1QUpJvRMQQl6TcJmzfB5wK/FLSfKoR8nJgLtU15O8DM0rfFVTXn8+TdG/p29MI+nUknSnpMWB9SY9JOq0/ziUiIvpGdi4RRvM6th7jvY49p9VhNCXPvo6IdiFptu0JPfXLlGf0SuopR0QMnCTl1YCku4B165o/antBK+KJiIiuJSmvBmzv2eoYIiKiZ7nRKyIiok1kpBy9snjJUg4+/YZWh9GlXOuOiKEuI+WIiIg2kaQcERHRJpKUIyIi2kSSchuRtJWka8ryOEnvr1n3QUmf78djvUvSHEkvS5rUX/uNiIi+S1JuI7Yft92ZIMcB769Zd53tM/rxcP8JTKF6fGdERLSBJOVuSPqJpNmSFpXyiUh6XtLZpW26pC1K+62Svi1pnqSFkvYo7ZuW/cyXNLPUQ0bSfqXvPElzS1GJ0WXbdYCvAJPL+smSpkg6X1KHpN9LWqPsZ6SkRyWtLWl7STeWmG+XNLbRudl+xPZ84JUm3odjJM2SNGvFsqWr/L5GRETXkpS79ze2xwMTgBMkbQaMBGbZ3hm4DfhSTf/1bY8DPgVcUtq+DMy1vRvwD8C/lvaTgeNK/3cC/9u5k1Jw4ovANNvjbE+rWbcUmAfsV5o+ANxk+yWqmsd/V2I+GbigP94E21NtT7A9YZ2RHf2xy4iI6EK+p9y9EyQdWpbfCIyhGll2JskrgWtr+v8AwPavJW0kaWNgX+CvSvuvJG0maSOqik9nSboKuNb2Y5KajWsaVZWoW4APAxdI2gDYB7i6Zj/1j9aMiIg2lqTcgKT9gYOAvW2/IOlWui6P6AbLXb1+dYV9hqQbqK4bz5B0MPBik+FdB/xTqbk8HvgV1Qj+mTLyjoiIISjT1411AE+XhDwW2Ku0rwF03ox1OPCbmm0mA0jaF1happpvB44o7fsDT9p+VtL2thfY/jpwD1B//fc5YMOuArP9fNnm28D1tlfafhZ4WNJh5ViStHufzz4iIgZdknJjNwJrSbofOAOYWdqXAXtIWggcQHVDVqcXJc0FLgSOLm2nAeMlzS/7+XhpP7Hc1DUfeAn4Rd3xbwF26rzRq4v4pgFH8upUOlTJ/2hJ9wKLgA81OjlJEyU9BhwGXCRpUaO+ERExOGQ3nGGNLkh63vYGXbTfCpxse9bgRzV4OrYe472OPafVYXQpz76OiHYlabbtCT31yzXl6JUxozqS/CIiBkiSci91NUou7fsPcihNkXQK1RR1rattf60V8URERGNJysNcSb5JwBERQ0Bu9IqIiGgTScoRERFtIkk5IiKiTSQpR0REtIkk5YiIiDaRpBwREdEmkpQjIiLaRJJyREREm0hSjoiIaBNJyhEREW0iSTkiIqJNJClHRES0idRTjl6R9BzwYKvj6IPNgSdbHUQfJfbWGKqxD9W4YXjHvp3tLXraSapERW892Eyh7nYjadZQjBsSe6sM1diHatyQ2CHT1xEREW0jSTkiIqJNJClHb01tdQB9NFTjhsTeKkM19qEaNyT23OgVERHRLjJSjoiIaBNJygGApD+T9KCk30n6fBfr15U0ray/S9LomnVfKO0PSjp4UAOn77FLeo+k2ZIWlN8HDJXYa9ZvK+l5SScPWtCs8n8vu0m6U9Ki8t6PGAqxS1pb0uUl5vslfWEw424y9ndJmiPpZUmT6tZ9XNLi8vPxwYv6T8fvU+ySxtX89zJf0uShEHfN+o0kPSbp/KYOaDs/q/kPsCbwH8CbgXWAe4Gd6vp8CriwLH8YmFaWdyr91wXeVPaz5hCJ/W3AVmV5F+C/hsr7XrP+GuBq4OShEDfV1zDnA7uX15sNof9eDgd+WJbXBx4BRrdZ7KOB3YB/BSbVtG8KPFR+b1KWNxkisb8VGFOWtwKWABu3e9w1678NfB84v5ljZqQcAHsAv7P9kO0VwA+BD9X1+RBweVm+BjhQkkr7D20vt/0w8Luyv8HS59htz7X9eGlfBKwnad1BibqyKu87kg4BHqaKfTCtStzvBebbvhfA9h9trxykuGHVYjcwUtJawHrACuDZwQkbaCJ224/Yng+8UrftwcDNtp+y/TRwM/BngxF00efYbf/W9uKy/DjwBNDjQzj6yaq850gaD7wB+GWzB0xSDoCtgUdrXj9W2rrsY/tlYCnVKKeZbQfSqsRe66+AObaXD1CcXelz7JI2AD4HfHkQ4qy3Ku/5WwFLuqlM+f39IMTbZVxFb2K/BlhGNVL7T+Cbtp8a6IC7iqvozb+1ofDvtEeS9qAasf5HP8XVkz7HLWkN4FtAry4t5YlesdqTtDPwdapR3FBxGnC27efLwHmoWAvYF5gIvABMlzTb9vTWhtWUPYCVVFOomwC3S/p32w+1NqzVg6RRwBXAx22/blTahj4F/Nz2Y735N5qRcgD8F/DGmtfblLYu+5Tpuw7gj01uO5BWJXYkbQP8GPiY7cH69P26uIrexL4ncKakR4ATgX+QdPwAx/u6mIrexP0Y8GvbT9p+Afg58PYBj7iLuIrexH44cKPtl2w/AcwABvORkKvyb20o/DttSNJGwA3AKbZn9nNs3VmVuPcGji//Rr8JfEzSGT1uNVgX+vPTvj9Uo5eHqG7U6ryZYee6Psfx2ptf/q0s78xrb/R6iMG9cWdVYt+49P/Lofa+1/U5jcG90WtV3vNNgDlUN0qtBfw78OdDJPbPAZeW5ZHAfcBu7RR7Td/LeP2NXg+X93+TsrzpEIl9HWA6cOJgxdsfcdetm0KTN3oN6gnmp31/gPcDv6W6VnNKafsK8MGyPILqLt/fAXcDb67Z9pSy3YPA+4ZK7MCpVNcI59X8bDkUYq/bx2kMYlLuh/9ejqS6OW0hcOYQ+u9lg9K+iCohf7YNY59INRuxjGp0v6hm278p5/Q74KihEnv57+Wlun+n49o97rp9TKHJpJwnekVERLSJXFOOiIhoE0nKERERbSJJOSIiok0kKUdERLSJJOWIiIg2kaQcEa8hyZKurHm9lqQ/SLq+h+02lvSpVTz2ZQ0q7XxF0kE9bLuupH+XNG+wKgnVn7OkrSRdMxjHjuEpSTki6i0DdpG0Xnn9Hpp7itHGVI8W7He2v2j733vo9rbSd5ztac3sV9KaqxjaxtScs+3Hbb/uQ0VEs5KUI6IrPwf+vCx/BPhB5wpJp9XWb5a0sNQcPgPYvoxUvyFp/9rRtaTzJU0py1+UdE/Zdmpn5atGakfQkh6R9OVS0GKBpLGStgSuBCaW428v6UBJc0ufSzorgJXtvy5pDnBYef3PZbtZkt5eCmb8h6RjyzYbSJpec8zOSkH15zxa0sKyzQhJl5b+cyW9u7RPkXStpBtV1TY+s29/ohiOkpQjois/BD4saQRVrdi7mtjm88B/lJHqZ3voe77tibZ3oSqD+IFexvek7bcD36F6mtkTwCeA222PoxrZXwZMtr0r1eMS/7Zm+z/afrvtH5bX/1m2u71sNwnYi1ercL0IHFqO+W7gW+WDRHfnfBzgcvyPAJeX9xNgHDAZ2BWYLOmNRJCkHBFdcFUfdjRVMvn5ABzi3ZLukrQAOIDqGeq9cW35PZsqzno7AA/b/m15fTnwrpr19dPb15XfC4C7bD9n+w/AckkbAwL+SdJ8qud1b01VJ7c7+1KN3rH9APB7qtKVANNtL7X9ItUjO7frYV+xmkjpxoho5Dqq6jb789r60y/z2g/0I+hal/3KaPECYILtRyWd1s0+Gumse72Svv1/bFmD/b1Ss9z5ei3gCGALYLztl0rln97G3NXxoO/nEMNQRsoR0cglwJdtL6hrf4RSblHS26kq6AA8B2xY0+/3wE7lruiNgQNLe2cye1LSBlRTxf3tQWC0pLeU1x8FbluF/XUAT5SE/G5eHdnWn3Ot26mSOZLeCmxb4opoKEk5Irpk+zHb53ax6kfAppIWAcdTVdDB9h+BGeXmrW/YfhT4N6pqUP8GzC39ngG+W9pvAu4ZgNhfBI4Cri5T5K8AF67CLq8CJpR9fQx4oBznNedct80FwBplm2nAFNvLiehGqkRFRES0iYyUIyIi2kSSckRERJtIUo6IiGgTScoRERFtIkk5IiKiTSQpR0REtIkk5YiIiDaRpBwREdEm/j849au+wYl3iwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs Feature Importance analysis\n",
    "\"\"\"\n",
    "file_name = 'Feature Importance/Figure 3'\n",
    "if not os.path.exists(file_name.split('/')[0]):\n",
    "    os.mkdir(file_name.split('/')[0])\n",
    "feature_importance(18, file_name, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a8bd265-79a5-4fd8-a792-416d68b33df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes mutual information and frequency of features for the feature selection\n",
    "\"\"\"\n",
    "def mutual_info(d_X, d_y):\n",
    "    mi_results = mutual_info_classif(d_X, d_y, discrete_features = True)\n",
    "    freq = np.array([sum(feat) for feat in d_X.T]) \n",
    "    return mi_results, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd7a3717-840d-453a-a75f-d0e1885fd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns an array of indexes of features that are supposed to be dropped because their mutual information is either zero or\n",
    "their frequency is lower than 2.\n",
    "\"\"\"\n",
    "\n",
    "def features_to_drop(X_data, y_data):\n",
    "    mi_results, freq = mutual_info(X_data, y_data)\n",
    "    idx_to_drop_1 = np.where(mi_results == 0) # covers also features which frequency equals zero\n",
    "    idx_to_drop_2 = np.where(freq == 1)\n",
    "    features_to_drop = np.unique(np.concatenate((idx_to_drop_1[0], idx_to_drop_2[0])))\n",
    "    return features_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace650ab-1714-423b-b43a-92ff7962447f",
   "metadata": {},
   "source": [
    "## Approximation algorithm and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb249984-db41-40aa-ba14-e17ff521a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities with a default classifier just to test functions below with those predictions.\n",
    "m1 = svm.SVC(probability = True, random_state = 1)\n",
    "m_fit = m1.fit(X_train_r, y_train_r)\n",
    "pred_test_proba = m_fit.predict_proba(X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5088b43-84bb-4a6d-85c7-7a8960392599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'b'): [0.05963306634841424, 0.9127323905808155, 0.027634543070770044]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Returns a list of dictionaries where each dictionary represents pairs of quantifiers (keys; tuple) and predicted class\n",
    "probabilities for those pairs (values; list) for each sentence.\n",
    "\"\"\"\n",
    "def get_prob_dict(test_data_annot, test_data_scope, test_pred):\n",
    "    results = []\n",
    "    beg = 0 \n",
    "    end = int((len(test_data_annot[0])*(len(test_data_annot[0]) - 1))/2)\n",
    "    for i in range(len(test_data_scope)):\n",
    "        sent_pred = test_pred[beg:end]\n",
    "        slownik = {k:list(sent_pred[j]) for (k, v), j in zip(test_data_scope[i].items(), range(len(test_data_scope[i])))}\n",
    "        results.append(slownik)\n",
    "        beg = end\n",
    "        if i < len(test_data_scope)-1:\n",
    "            end += len(test_data_annot[i+1])*(len(test_data_annot[i+1])-1)/2\n",
    "            end = int(end)\n",
    "    return results\n",
    "d_test = get_prob_dict(test_annot_r, test_scope_r, pred_test_proba)\n",
    "d_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9bff96-0fdd-449e-8ff8-b5d8e7a8134c",
   "metadata": {},
   "source": [
    "## Create gold and predicted graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b89d66f-6589-4a76-8cfa-4decb8ad504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns gold transitive directed acyclic graph.\n",
    "\"\"\"\n",
    "def create_nx_gold_tdag(scope):\n",
    "    G = nx.DiGraph()\n",
    "    for key, value in scope.items():\n",
    "        G.add_node(key[0])\n",
    "        G.add_node(key[1])\n",
    "        if value == str(1) or value == 1:\n",
    "            G.add_edge(key[0], key[1])\n",
    "        elif value == str(2) or value == 2:\n",
    "            G.add_edge(key[1], key[0])\n",
    "    G_test = nx.transitive_closure(G)\n",
    "    if not nx.is_isomorphic(G, G_test):\n",
    "        print(\"STOP! This should not have happened\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "811f7912-cebf-4d19-b4f6-34f4d3af7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of nodes and a list of edges returned by the approximation algorithm, this function returns an instance\n",
    "of a prediced transitive directed acyclic graph created with the module NetworkX.\n",
    "\"\"\"\n",
    "\n",
    "def create_nx_pred_tdag(pred_sent):\n",
    "    nodes, edges = create_pred_tdag(pred_sent)\n",
    "    tdag_pred = nx.DiGraph()\n",
    "    for node in nodes:\n",
    "        tdag_pred.add_node(node)  \n",
    "    for edge in edges:\n",
    "        tdag_pred.add_edge(edge[0], edge[1])   \n",
    "    return tdag_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60165208-ba78-4137-a0a9-8818622d57e4",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba743285",
   "metadata": {
    "id": "ba743285"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions defined in this cell are responsible for computing evalutation metric: similarity.\n",
    "\"\"\"\n",
    "\n",
    "# Similarity measure for a sentence's scope\n",
    "def sort_edges(g_edges):\n",
    "    g_edges_final = []\n",
    "    for edge in g_edges:\n",
    "        if edge[0] > edge[1]:\n",
    "            g_edges_final.append((edge[1], edge[0]))\n",
    "        else:\n",
    "            g_edges_final.append(edge)\n",
    "    return g_edges_final\n",
    "\n",
    "def eval_similar(g_pred, g_gold):\n",
    "    m1 = len(set(g_pred.edges).intersection(set(g_gold.edges)))\n",
    "    g_pred_comp_und = nx.complement(g_pred.to_undirected())\n",
    "    g_gold_comp_und = nx.complement(g_gold.to_undirected())\n",
    "    \n",
    "    # When we get an undirected version of a graph, it does not matter if edges are in order (q1, q2) or (q2, q1). \n",
    "    # However, they need to be in the same order in the case of gold graph and predicted graph.\n",
    "    g_gold_comp_und_edges_sorted = sort_edges(g_gold_comp_und.edges)\n",
    "    g_pred_comp_und_edges_sorted = sort_edges(g_pred_comp_und.edges)\n",
    "    \n",
    "    m2 = len(set(g_pred_comp_und_edges_sorted).intersection(set(g_gold_comp_und_edges_sorted)))\n",
    "    \n",
    "    if not len(g_pred.nodes) == len(g_gold.nodes):\n",
    "        print('STOP! Something is wrong here!')\n",
    "        \n",
    "    tot_edges = len(g_gold.nodes) * (len(g_gold.nodes) - 1)/2\n",
    "    \n",
    "    eval_similar = (m1 + m2) / tot_edges\n",
    "    \n",
    "    return eval_similar\n",
    "\n",
    "# Similarity measure for the whole development or test set\n",
    "def tot_eval_similar(sent_pred, dev_test_scope):\n",
    "    tot_similar_score = 0\n",
    "    for sent_p, sent_g in zip(sent_pred, dev_test_scope):\n",
    "        G_pred = create_nx_pred_tdag(sent_p)\n",
    "        G_gold = create_nx_gold_tdag(sent_g)\n",
    "        s = eval_similar(G_pred, G_gold)\n",
    "        tot_similar_score += s\n",
    "    if not len(dev_test_scope) == len(sent_pred):\n",
    "        print('STOP! Something is wrong here!')        \n",
    "    similarity = tot_similar_score/len(dev_test_scope) * 100\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7GGyGPpSUlHn",
   "metadata": {
    "id": "7GGyGPpSUlHn"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions defined in this cell are responsible for computing evalutation metrics: precision and recall.\n",
    "\"\"\"\n",
    "\n",
    "# Precision and recall for a sentence's scope\n",
    "def eval_prec_recall(g_pred, g_gold):\n",
    "    if not len(g_pred.nodes) == len(g_gold.nodes):\n",
    "        print('STOP! Something is wrong here!')\n",
    "    \n",
    "    empty = False\n",
    "    \n",
    "    m1 = len(set(g_pred.edges).intersection(set(g_gold.edges)))\n",
    "    \n",
    "    m_precision = len(set(g_pred.edges))\n",
    "    m_recall = len(set(g_gold.edges))\n",
    "\n",
    "# There are sentences in the corpus with no intercation relation between quantifiers only. There are no edges in the graph\n",
    "# representation of those sentences. Hence, we do not include those sentences in the computation of precision and recall.\n",
    "# Also, it might be the case for a sentence that a gold scoping has edges but predicted scoping does not. Those sentence's\n",
    "# are also not considered in computation of precision so that both precision and recall are computed on the same number\n",
    "# of sentences.\n",
    "\n",
    "    if m_precision == 0 or m_recall == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        empty = True\n",
    "    else:\n",
    "        precision = m1/m_precision\n",
    "        recall = m1/m_recall\n",
    "    \n",
    "    return precision, recall, empty\n",
    "\n",
    "\n",
    "# Precision and recall measures for the whole development or test set\n",
    "def tot_prec_rec(sent_pred, dev_test_scope):\n",
    "    tot_precision = 0\n",
    "    tot_recall = 0\n",
    "    no_edges_sent = 0\n",
    "    for sent_p, sent_g in zip(sent_pred, dev_test_scope):\n",
    "        G_pred = create_nx_pred_tdag(sent_p)\n",
    "        G_gold = create_nx_gold_tdag(sent_g)\n",
    "        p, r, empt = eval_prec_recall(G_pred, G_gold)\n",
    "        if empt:\n",
    "            no_edges_sent += 1\n",
    "        tot_precision += p\n",
    "        tot_recall += r\n",
    "\n",
    "    if not len(dev_test_scope) == len(sent_pred):\n",
    "        print('STOP! Something is wrong here!')  \n",
    "        \n",
    "    precision_final = tot_precision/(len(dev_test_scope) - no_edges_sent) * 100\n",
    "    recall_final = tot_recall/(len(dev_test_scope) - no_edges_sent) * 100\n",
    "    return precision_final, recall_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65992330-1e1e-4327-b609-31f9c79f13df",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "047f27e8-358b-4851-ad29-b9fb32056824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152, 237)\n",
      "78.57843137254903\n",
      "(84.48571428571428, 87.95238095238095)\n"
     ]
    }
   ],
   "source": [
    "cols, data_X, data_y = prep_data(ALL_ANNOTATIONS, ALL_SCOPES, ALL_ROLES, ALL_LEX, ALL_PREP, False, False)\n",
    "idx_drop = features_to_drop(data_X, data_y)\n",
    "\n",
    "print(X_train_r.shape)\n",
    "X_train_rrr = np.delete(X_train_r, idx_drop, axis = 1)\n",
    "X_test_rrr = np.delete(X_test_r, idx_drop, axis = 1)\n",
    "\n",
    "m2 = svm.SVC(probability = True, random_state = 1)\n",
    "m_fit_proba = m2.fit(X_train_rrr,  y_train_r)\n",
    "pred_test_proba = m_fit_proba.predict_proba(X_test_rrr)\n",
    "\n",
    "prob_dict = get_prob_dict(test_annot_r, test_scope_r, pred_test_proba)\n",
    "print(tot_eval_similar(prob_dict, test_scope_r))\n",
    "print(tot_prec_rec(prob_dict, test_scope_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4ba92-607a-44e0-8b00-c639cfdfed88",
   "metadata": {},
   "source": [
    "### WIDE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5873570d-d6a8-4863-a7fd-f1b4f19fec26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {0: 0, 1: 30, 2: 0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This functions returns a dict with an information of most frequent label in the training set in all 30 different data splits.\n",
    "In all 30 cases it is wide scope.\n",
    "\"\"\"\n",
    "\n",
    "def check_most_frequent(data_annots, data_scopes):\n",
    "    most_freq_dict = defaultdict(int)\n",
    "    most_freq_dict[0] = 0\n",
    "    most_freq_dict[1] = 0\n",
    "    most_freq_dict[2] = 0\n",
    "    nb_outer = 30\n",
    "    for i in range(nb_outer):\n",
    "        train_annot, train_scope, _, _ = split_data(data_annots, data_scopes, i)\n",
    "        wide = 0\n",
    "        narrow = 0\n",
    "        incomp = 0\n",
    "        for sent in train_scope:\n",
    "            for key, value in sent.items():\n",
    "                if value == '1':\n",
    "                    wide += 1\n",
    "                elif value == '2':\n",
    "                    narrow += 1\n",
    "                else:\n",
    "                    incomp += 1\n",
    "        most_freq_class = [incomp, wide, narrow].index(max([incomp, wide, narrow]))\n",
    "        most_freq_dict[most_freq_class] += 1\n",
    "    return most_freq_dict\n",
    "\n",
    "check_most_frequent(ALL_ANNOTATIONS, ALL_SCOPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a00b877-15aa-4e33-a43d-bda268c3c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function converts list of scopes into the most frequent label - wide scope.\n",
    "\"\"\"\n",
    "def convert_to_wide(data_scopes):\n",
    "    all_scopes_wide = []\n",
    "    for sent in data_scopes:\n",
    "        d = {}\n",
    "        for key, value in sent.items():\n",
    "            d[key] = 1\n",
    "        all_scopes_wide.append(d)\n",
    "    return all_scopes_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d536bd5d-3031-4a0c-8eee-54c04e7c7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function provides results of the WIDE measure (as defined in the paper) that is a pseudo-model that labels each\n",
    "pairwise comparison as the most frequent label - wide scope.\n",
    "\"\"\"\n",
    "\n",
    "def eval_wide_baseline(all_annot, all_scope):\n",
    "    nb_outer = 30\n",
    "    results = defaultdict(list)\n",
    "    for i in range(nb_outer):\n",
    "        tot_similar = 0\n",
    "        tot_prec = 0\n",
    "        tot_rec = 0\n",
    "        no_edges = 0\n",
    "        _, _, test_annot, test_scope = split_data(all_annot, all_scope, i)\n",
    "        test_scope_wide = convert_to_wide(test_scope)\n",
    "        for g_scope, w_scope in zip(test_scope, test_scope_wide):\n",
    "            gold_graph = create_nx_gold_tdag(g_scope)\n",
    "            wide_graph = create_nx_gold_tdag(w_scope)\n",
    "            sim = eval_similar(wide_graph, gold_graph)\n",
    "            prec, rec, empty = eval_prec_recall(wide_graph, gold_graph)\n",
    "            tot_similar += sim\n",
    "            tot_prec += prec\n",
    "            tot_rec += rec\n",
    "            if empty:\n",
    "                no_edges += 1            \n",
    "        \n",
    "        final_sim = tot_similar/len(test_scope) * 100\n",
    "        final_prec = tot_prec/(len(test_scope) - no_edges) * 100\n",
    "        final_rec = tot_rec/(len(test_scope) - no_edges) * 100\n",
    "        results['similarity'].append(final_sim)\n",
    "        results['precision'].append(final_prec)\n",
    "        results['recall'].append(final_rec)\n",
    "    return results\n",
    "\n",
    "results_wide = eval_wide_baseline(ALL_ANNOTATIONS, ALL_SCOPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d5b2f4d-3b58-4350-b346-7f04fe1c9e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIDE \n",
      " similarity:  (64.82102007469653, 3.4649593128435696) precision:  (69.00110110214177, 3.3869269450169717) recall:  (73.72693257625544, 3.2912124159952394)\n"
     ]
    }
   ],
   "source": [
    "similarity_results = (np.mean(results_wide['similarity']), np.std(results_wide['similarity']))\n",
    "precision_results = (np.mean(results_wide['precision']), np.std(results_wide['precision']))\n",
    "recal_results = (np.mean(results_wide['recall']), np.std(results_wide['recall']))\n",
    "print('WIDE', '\\n', 'similarity: ', similarity_results, 'precision: ', precision_results, 'recall: ', recal_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df189e63-54a8-4516-9ce2-f102aba6cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "if not os.path.exists(os.path.join(current_dir, 'Results')):\n",
    "    os.mkdir(os.path.join(current_dir, 'Results'))\n",
    "with open('Results/results_wide.json', 'w') as fp:\n",
    "    json.dump(results_wide, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d299bf1",
   "metadata": {
    "id": "4d299bf1"
   },
   "source": [
    "# Training and optymization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8225ef55-cb03-4bbd-96fd-0d0a9ba53cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and hyperparameeters to use for optimization and training\n",
    "regularization = [0.1, 1, 5, 10, 25, 50, 100]\n",
    "gamma = [1., 0.5, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "kernel = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "class_weight = [None, 'balanced']\n",
    "nb_outer = 30\n",
    "nb_inner = 5\n",
    "\n",
    "# DEV-RUN\n",
    "#regularization = [1.]\n",
    "#gamma = [0.5]\n",
    "#kernel = ['linear']\n",
    "#class_weight = [None, 'balanced']\n",
    "#nb_outer = 2\n",
    "#nb_inner = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "opKei7btbCug",
   "metadata": {
    "id": "opKei7btbCug"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given certain hyperparaeters, training and testing data, trains SVM classifier and returns predicted probabilities for \n",
    "the test set.\n",
    "\"\"\"\n",
    "def train_pred_opt(X_train, y_train, X_test, ker, gam, reg, element):\n",
    "    m = svm.SVC(kernel = ker, gamma = gam, C = reg, class_weight = element, probability = True, random_state = 1)\n",
    "    m_fit = m.fit(X_train, y_train)\n",
    "    pred = m_fit.predict_proba(X_test)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "akpch_v7qoQC",
   "metadata": {
    "id": "akpch_v7qoQC"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function returns average scores over a number of runs.\n",
    "\"\"\"\n",
    "def get_averages(scores_opt):\n",
    "    scores_averaged = {}\n",
    "    for key, value in scores_opt.items():\n",
    "        scores_averaged[key] = (np.mean(value), np.std(value))\n",
    "    return scores_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3da50c49",
   "metadata": {
    "id": "3da50c49"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function defines the training and optimisation procedures in a nested cross-validation scenario, as described in the\n",
    "paper, and combines all steps introduced previously such as combines quantifier lexicalizations into groups or \n",
    "performes feaature selection.\n",
    "\n",
    "This function returns lists of similarity, precision and recall scores of a given training scenario.  Additionally,\n",
    "a list of hyperparameters chosen in the inner loop (optimization) for each of the 30 runs is returned.\n",
    "\"\"\"\n",
    "\n",
    "def train_all(prep, ss2, ssss2):\n",
    "    scores_inner = defaultdict(list)\n",
    "    scores_similarity = []\n",
    "    scores_prec = []\n",
    "    scores_rec = []\n",
    "    best_params = []\n",
    "\n",
    "    _, X_data, y_data = prep_data(ALL_ANNOTATIONS, ALL_SCOPES, ALL_ROLES, ALL_LEX, prep, ss2, ssss2)\n",
    "    idx_drop = features_to_drop(X_data, y_data)\n",
    "    i = 0\n",
    "    for i in range(nb_outer):\n",
    "        if i % 5 == 0:\n",
    "            print(i)\n",
    "        train_annot, train_scope, test_annot, test_scope = split_data(ALL_ANNOTATIONS, ALL_SCOPES, i)\n",
    "        for k in kernel:\n",
    "            if k == 'linear':\n",
    "                for r, el in itertools.product(regularization, class_weight):\n",
    "                    kf = KFold(n_splits = nb_inner, shuffle = True, random_state = 1)\n",
    "                    for train_idx, test_idx in kf.split(train_annot):\n",
    "                        train_annot_in = [train_annot[idx] for idx in train_idx]\n",
    "                        test_annot_in = [train_annot[idx] for idx in test_idx]\n",
    "                        train_scope_in = [train_scope[idx] for idx in train_idx]\n",
    "                        test_scope_in = [train_scope[idx] for idx in test_idx]\n",
    "                \n",
    "                        cols_in, X_train_in, y_train_in = prep_data(train_annot_in, train_scope_in, ALL_ROLES, ALL_LEX,\n",
    "                                                                    prep, ss2, ssss2)\n",
    "                        _, X_test_in, y_test_in = prep_data(test_annot_in, test_scope_in, ALL_ROLES, ALL_LEX,\n",
    "                                                            prep, ss2, ssss2)\n",
    "                \n",
    "                        X_train_in = np.delete(X_train_in, idx_drop, axis = 1)\n",
    "                        X_test_in = np.delete(X_test_in, idx_drop, axis = 1)\n",
    "            \n",
    "                        # Linear kernel does not make use of gamma parameter; here '1.' is just a placeholder.\n",
    "                        pred_test_in = train_pred_opt(X_train_in, y_train_in, X_test_in, k, 1., r, el)\n",
    "                \n",
    "                        pred_dict_in = get_prob_dict(test_annot_in, test_scope_in, pred_test_in)\n",
    "                \n",
    "                        s_test_in = tot_eval_similar(pred_dict_in, test_scope_in)\n",
    "                        scores_inner[(k, 1., r, el)].append(s_test_in)           \n",
    "            else:\n",
    "                for g, r, el in itertools.product(gamma, regularization, class_weight):\n",
    "                    kf = KFold(n_splits = nb_inner, shuffle = True, random_state = 1)\n",
    "                    for train_idx, test_idx in kf.split(train_annot):\n",
    "                        train_annot_in = [train_annot[idx] for idx in train_idx]\n",
    "                        test_annot_in = [train_annot[idx] for idx in test_idx]\n",
    "                        train_scope_in = [train_scope[idx] for idx in train_idx]\n",
    "                        test_scope_in = [train_scope[idx] for idx in test_idx]\n",
    "                \n",
    "                        cols_in, X_train_in, y_train_in = prep_data(train_annot_in, train_scope_in, ALL_ROLES, ALL_LEX,\n",
    "                                                                    prep, ss2, ssss2)\n",
    "                        _, X_test_in, y_test_in = prep_data(test_annot_in, test_scope_in, ALL_ROLES, ALL_LEX,\n",
    "                                                            prep, ss2, ssss2)\n",
    "                \n",
    "                        X_train_in = np.delete(X_train_in, idx_drop, axis = 1)\n",
    "                        X_test_in = np.delete(X_test_in, idx_drop, axis = 1)\n",
    "            \n",
    "                        pred_test_in = train_pred_opt(X_train_in, y_train_in, X_test_in, k, g, r, el)\n",
    "                \n",
    "                        pred_dict_in = get_prob_dict(test_annot_in, test_scope_in, pred_test_in)\n",
    "                \n",
    "                        s_test_in = tot_eval_similar(pred_dict_in, test_scope_in)\n",
    "                        scores_inner[(k, g, r, el)].append(s_test_in)\n",
    "            \n",
    "        \n",
    "        scores_inner_avg = get_averages(scores_inner)\n",
    "        \n",
    "        # By default the first item in the tuple is used for sorting.\n",
    "        best_params_inner = max(scores_inner_avg, key = scores_inner_avg.get) \n",
    "        \n",
    "        _, X_train, y_train = prep_data(train_annot, train_scope, ALL_ROLES, ALL_LEX, prep, ss2, ssss2)\n",
    "        _, X_test, y_test = prep_data(test_annot, test_scope, ALL_ROLES, ALL_LEX, prep, ss2, ssss2)\n",
    "        \n",
    "        X_train = np.delete(X_train, idx_drop, axis = 1)\n",
    "        X_test = np.delete(X_test, idx_drop, axis = 1)\n",
    "        \n",
    "        k_best, g_best, r_best, el_best = best_params_inner\n",
    "        \n",
    "        pred_test = train_pred_opt(X_train, y_train, X_test, k_best, g_best, r_best, el_best)\n",
    "        \n",
    "        pred_dict = get_prob_dict(test_annot, test_scope, pred_test)\n",
    "        \n",
    "        s_test = tot_eval_similar(pred_dict, test_scope)\n",
    "        p_test, r_test = tot_prec_rec(pred_dict, test_scope)\n",
    "        scores_similarity.append(s_test)\n",
    "        scores_prec.append(p_test)\n",
    "        scores_rec.append(r_test)\n",
    "        best_params.append(best_params_inner + (i,))\n",
    "        \n",
    "    return scores_similarity, scores_prec, scores_rec, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a66639ff-eeb9-4ee9-8879-fb88debee900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "0\n",
      "prep\n",
      "0\n",
      "ss2\n",
      "0\n",
      "ssss2\n",
      "prep ss2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run the training and save results of each training scenario to a different json file.\n",
    "\"\"\"\n",
    "for option in ['baseline', 'prep', 'ss2', 'ssss2', 'prep ss2']:\n",
    "    print(option)\n",
    "    if option == 'baseline':\n",
    "        scores_similarity, scores_prec, scores_rec, params = train_all(False, False, False)\n",
    "    elif option == 'prep':\n",
    "        scores_similarity, scores_prec, scores_rec, params = train_all(ALL_PREP, False, False) \n",
    "    elif option == 'ss2':\n",
    "        scores_similarity, scores_prec, scores_rec, params = train_all(False, ALL_SS2, False) \n",
    "    elif option == 'ss1ss2':\n",
    "        scores_similarity, scores_prec, scores_rec, params = train_all(False, False, ALL_SSSS2) \n",
    "    elif option == 'prep ss2':\n",
    "        scores_similarity, scores_prec, scores_rec, params = train_all(ALL_PREP, ALL_SS2, False)\n",
    "        \n",
    "    results = defaultdict(list)\n",
    "    results['similarity'] = scores_similarity\n",
    "    results['precision'] = scores_prec\n",
    "    results['recall'] = scores_rec\n",
    "    results['params'] = params\n",
    "    \n",
    "    file_name = os.path.join('Results', 'results_' + option + '.json')\n",
    "    with open(file_name, 'w') as fp:\n",
    "        json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FyF-tPOy2Wml",
   "metadata": {
    "id": "FyF-tPOy2Wml"
   },
   "source": [
    "## Read and restructure results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "NXAZdwfs2ayE",
   "metadata": {
    "id": "NXAZdwfs2ayE"
   },
   "outputs": [],
   "source": [
    "# Read results from json files\n",
    "\n",
    "with open(\"Results/results_baseline.json\") as f:\n",
    "    results_baseline = json.load(f)\n",
    "\n",
    "with open(\"Results/results_prep.json\") as f:\n",
    "    results_prep = json.load(f)\n",
    "\n",
    "with open(\"Results/results_ss2.json\") as f:\n",
    "    results_ss2 = json.load(f)\n",
    "\n",
    "with open(\"Results/results_ssss2.json\") as f:\n",
    "    results_ssss2 = json.load(f)\n",
    "\n",
    "with open(\"Results/results_prep ss2.json\") as f:\n",
    "    results_prepss2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "jSsyTWnD3YJq",
   "metadata": {
    "id": "jSsyTWnD3YJq"
   },
   "outputs": [],
   "source": [
    "# Prepare a dict of combined averaged results\n",
    "all_results = {}\n",
    "all_results['baseline'] = {}\n",
    "all_results['prep'] = {}\n",
    "all_results['ss2'] = {}\n",
    "all_results['ssss2'] = {}\n",
    "all_results['prep_ss2'] = {}\n",
    "\n",
    "all_results['baseline'].update({k:(np.mean(v), np.std(v)) for k, v in results_baseline.items() if k != 'params'})\n",
    "all_results['prep'].update({k:(np.mean(v), np.std(v)) for k, v in results_prep.items() if k != 'params'})\n",
    "all_results['ss2'].update({k:(np.mean(v), np.std(v)) for k, v in results_ss2.items() if k != 'params'})\n",
    "all_results['ssss2'].update({k:(np.mean(v), np.std(v)) for k, v in results_ssss2.items() if k != 'params'})\n",
    "all_results['prep_ss2'].update({k:(np.mean(v), np.std(v)) for k, v in results_prepss2.items() if k != 'params'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07s32JGr7Wi1",
   "metadata": {
    "id": "07s32JGr7Wi1"
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(all_results, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "pUB81XzJGEeU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1638213039790,
     "user": {
      "displayName": "Aleksander Leczkowski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05469543576572858132"
     },
     "user_tz": -60
    },
    "id": "pUB81XzJGEeU",
    "outputId": "c34c6c64-61eb-4ef1-d765-e75a2316352b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>(80.52923669467786, 3.1277811547971903)</td>\n",
       "      <td>(84.95888824786944, 2.908579477866137)</td>\n",
       "      <td>(86.24457914416361, 2.7781348438062072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>(81.98541083099907, 2.450806438627136)</td>\n",
       "      <td>(86.42235384881646, 2.4325973947708994)</td>\n",
       "      <td>(88.05127732411069, 2.140182730720683)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ss2</th>\n",
       "      <td>(83.5672268907563, 2.4549857894772114)</td>\n",
       "      <td>(88.49979334256541, 1.8844425503810596)</td>\n",
       "      <td>(89.88065782613201, 1.761961073909889)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssss2</th>\n",
       "      <td>(83.45413165266108, 2.6924276062564787)</td>\n",
       "      <td>(88.22896088273434, 2.146172113215445)</td>\n",
       "      <td>(89.47506160421176, 1.9234082180867302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_ss2</th>\n",
       "      <td>(83.0107376283847, 2.289591007884588)</td>\n",
       "      <td>(87.5211382294241, 2.172304153595009)</td>\n",
       "      <td>(89.12269940176529, 1.8787444892167195)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       similarity  \\\n",
       "baseline  (80.52923669467786, 3.1277811547971903)   \n",
       "prep       (81.98541083099907, 2.450806438627136)   \n",
       "ss2        (83.5672268907563, 2.4549857894772114)   \n",
       "ssss2     (83.45413165266108, 2.6924276062564787)   \n",
       "prep_ss2    (83.0107376283847, 2.289591007884588)   \n",
       "\n",
       "                                        precision  \\\n",
       "baseline   (84.95888824786944, 2.908579477866137)   \n",
       "prep      (86.42235384881646, 2.4325973947708994)   \n",
       "ss2       (88.49979334256541, 1.8844425503810596)   \n",
       "ssss2      (88.22896088273434, 2.146172113215445)   \n",
       "prep_ss2    (87.5211382294241, 2.172304153595009)   \n",
       "\n",
       "                                           recall  \n",
       "baseline  (86.24457914416361, 2.7781348438062072)  \n",
       "prep       (88.05127732411069, 2.140182730720683)  \n",
       "ss2        (89.88065782613201, 1.761961073909889)  \n",
       "ssss2     (89.47506160421176, 1.9234082180867302)  \n",
       "prep_ss2  (89.12269940176529, 1.8787444892167195)  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "rmby_a-Yy4bk",
   "metadata": {
    "id": "rmby_a-Yy4bk"
   },
   "outputs": [],
   "source": [
    "# Prepare data for statistical analysis.\n",
    "df_baseline = pd.DataFrame({'similarity': results_baseline['similarity'], 'precision': results_baseline['precision'],\n",
    "                            'recall': results_baseline['recall'], 'group': np.repeat(['results_baseline'], repeats=30)})\n",
    "df_prep = pd.DataFrame({'similarity': results_prep['similarity'], 'precision': results_prep['precision'], \n",
    "                        'recall': results_prep['recall'], 'group': np.repeat(['results_prep'], repeats=30)}) \n",
    "df_ss2 = pd.DataFrame({'similarity': results_ss2['similarity'], 'precision': results_ss2['precision'],\n",
    "                            'recall': results_ss2['recall'], 'group': np.repeat(['results_ss2'], repeats=30)})\n",
    "df_ssss2 = pd.DataFrame({'similarity': results_ssss2['similarity'], 'precision': results_ssss2['precision'], \n",
    "                         'recall': results_ssss2['recall'], 'group': np.repeat(['results_ssss2'], repeats=30)}) \n",
    "df_prepss2 = pd.DataFrame({'similarity': results_prepss2['similarity'], 'precision': results_prepss2['precision'], \n",
    "                           'recall': results_prepss2['recall'], 'group': np.repeat(['results_prepss2'], repeats=30)}) \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0265bcce-c30a-45b7-8060-9ec264de9e7e",
   "metadata": {
    "id": "ssV_M1yS1pZz"
   },
   "source": [
    "# Create a dataframe of results prepared for statistical analysis\n",
    "df_to_analysis = pd.concat([df_baseline, df_prep, df_ss2, df_ssss2, df_prepss2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TkbK8-ceZiV4",
   "metadata": {
    "id": "TkbK8-ceZiV4"
   },
   "outputs": [],
   "source": [
    "# Save data ready for statistical analysis to an excel file (analysis is performed in R)\n",
    "with pd.ExcelWriter('Results/results_to_stat_analysis.xlsx', mode='w') as writer:  \n",
    "    df_to_analysis.to_excel(writer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "If2SZdN5N-K6",
    "fd6edaf6",
    "0059fa6f",
    "938cf6ec"
   ],
   "name": "licencjat.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
